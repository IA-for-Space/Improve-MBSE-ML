{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rICw0MTsMtam",
    "outputId": "4acf6428-30d0-4699-8dbe-e002169aa480"
   },
   "outputs": [],
   "source": [
    "#!pip install polaris-ml\n",
    "#!pip install fets\n",
    "#!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlwcETrdgSBZ",
    "outputId": "80d937e4-3ea8-4554-9ccd-bb2dafc31ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./lightsail2_dataset/2127458.txt', './lightsail2_dataset/2127459.txt', './lightsail2_dataset/2127460.txt', './lightsail2_dataset/2127461.txt', './lightsail2_dataset/2127462.txt']\n",
      "['./mars_express_dataset/context--2008-08-22_2010-07-10--dmop.csv', './mars_express_dataset/context--2008-08-22_2010-07-10--evtf.csv', './mars_express_dataset/context--2008-08-22_2010-07-10--ftl.csv', './mars_express_dataset/context--2008-08-22_2010-07-10--ltdata.csv', './mars_express_dataset/context--2010-07-10_2012-05-27--dmop.csv']\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "lista_archivos_lightsail = [\"./lightsail2_dataset/\" + x for x in os.listdir(\"./lightsail2_dataset\") if x[-3:] == \"txt\"]\n",
    "lista_archivos_marsexpress = [\"./mars_express_dataset/\" + x for x in os.listdir(\"./mars_express_dataset/\") if x[-3:] == \"csv\"]\n",
    "print(lista_archivos_lightsail[:5])\n",
    "print(lista_archivos_marsexpress[:5])\n",
    "\n",
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKOK2W_sacnM",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DATASET PARA LECTURA HUMANA DEL LIGHTSAIL\n",
    "\n",
    "def read_human_from_txt_lightsail(lista_archivos):\n",
    "\n",
    "  etiquetas = [\"Observed_at\", \"Posted_at\"]\n",
    "\n",
    "  dataset = {}\n",
    "\n",
    "  dataset[etiquetas[0]] = []\n",
    "  dataset[etiquetas[1]] = []\n",
    "\n",
    "  archivo1 = open(lista_archivos[0], \"r\")\n",
    "\n",
    "  for linea in archivo1:\n",
    "    if \"Observed at\" in linea:\n",
    "      valor = linea.split(\"at:\")[1].strip()\n",
    "      dataset[\"Observed_at\"].append(valor)\n",
    "    elif \"Posted at\" in linea:\n",
    "      valor = linea.split(\"at:\")[1].strip()\n",
    "      dataset[\"Posted_at\"].append(valor)\n",
    "    elif \":\" in linea and \"=\" in linea:\n",
    "      etiqueta = linea.split(\":\")[1].split(\"=\")[0].strip().replace(\" \", \"_\").replace(\"[\", \"_\").replace(\"]\", \"_\").replace(\"<\", \"_\")\n",
    "      valor = linea.split(\":\")[1].split(\"=\")[1].split(\"[\")[0].strip()\n",
    "      dataset[etiqueta] = []\n",
    "      dataset[etiqueta].append(valor)\n",
    "\n",
    "  for nombre_archivo in lista_archivos[1:]:\n",
    "    archivo = open(nombre_archivo, \"r\")\n",
    "    for linea in archivo:\n",
    "      if \"Observed at\" in linea:\n",
    "        valor = linea.split(\"at:\")[1].strip()\n",
    "        dataset[\"Observed_at\"].append(valor)\n",
    "      elif \"Posted at\" in linea:\n",
    "        valor = linea.split(\"at:\")[1].strip()\n",
    "        dataset[\"Posted_at\"].append(valor)\n",
    "      elif \":\" in linea and \"=\" in linea:\n",
    "        etiqueta = linea.split(\":\")[1].split(\"=\")[0].strip().replace(\" \", \"_\").replace(\"[\", \"_\").replace(\"]\", \"_\").replace(\"<\", \"_\")\n",
    "        valor = linea.split(\":\")[1].split(\"=\")[1].split(\"[\")[0].strip()\n",
    "        dataset[etiqueta].append(valor)\n",
    "\n",
    "  df = pd.DataFrame(dataset.values(), dataset.keys())\n",
    "  df = df.transpose()\n",
    "  return df\n",
    "\n",
    "print(\"Ok\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "OSL_Yph0WzBZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "#LECTURA DE LOS DATASETS DE LIGHTSAIL2 Y MARS EXPRESS\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def transform_unix_to_utc(series):\n",
    "  if len(series) > 0:\n",
    "    new_series = [str(datetime.utcfromtimestamp(x/1000))[:-3] for x in series]\n",
    "    return new_series\n",
    "  else:\n",
    "    return []\n",
    "\n",
    "def read_from_txt_lightsail(lista_archivos):\n",
    "  dataset = {}\n",
    "  archivo1 = open(lista_archivos[0], \"r\")\n",
    "  kvp_form = False\n",
    "\n",
    "  for linea in archivo1:\n",
    "    if \"KVP form:\" in linea:\n",
    "      kvp_form = True\n",
    "    if kvp_form is True and \"=\" in linea:\n",
    "        etiqueta = linea.split(\"=\")[0].strip()\n",
    "        valor = float(linea.split(\"=\")[1].split(\",\")[0].strip())\n",
    "        dataset[etiqueta] = []\n",
    "        dataset[etiqueta].append(valor)\n",
    "\n",
    "  for nombre_archivo in lista_archivos[1:]:\n",
    "    archivo = open(nombre_archivo, \"r\")\n",
    "    kvp_form = False\n",
    "    for linea in archivo:\n",
    "      if \"KVP form:\" in linea:\n",
    "        kvp_form = True\n",
    "      if kvp_form is True and \"=\" in linea:\n",
    "        etiqueta = linea.split(\"=\")[0].strip()\n",
    "        valor = float(linea.split(\"=\")[1].split(\",\")[0].strip())\n",
    "        dataset[etiqueta].append(valor)\n",
    "\n",
    "  df = pd.DataFrame(dataset.values(), dataset.keys())\n",
    "  df = df.transpose()\n",
    "  return df\n",
    "\n",
    "\n",
    "def read_from_ut_ms(lista_archivos):\n",
    "  columnas = []\n",
    "  for archivo in lista_archivos:\n",
    "    df1 = pd.read_csv(archivo)\n",
    "    columnas += list(df1.columns)\n",
    "    columnas = list(set(columnas))\n",
    "\n",
    "  df = pd.DataFrame(columns=columnas)\n",
    "  df = df.loc[:, ~df.columns.duplicated()]\n",
    "  for archivo in lista_archivos:\n",
    "    df2 = pd.read_csv(archivo)\n",
    "    df2[\"date\"] = transform_unix_to_utc(df2[\"ut_ms\"])\n",
    "    df = df.append(df2)\n",
    "  return df.head(1000)\n",
    "\n",
    "def read_from_utb_ms(lista_archivos):\n",
    "  columnas = []\n",
    "  for archivo in lista_archivos:\n",
    "    df1 = pd.read_csv(archivo)\n",
    "    columnas = list(df1.columns)\n",
    "    columnas.append(\"date\")\n",
    "  df = pd.DataFrame(columns=columnas)\n",
    "  for archivo in lista_archivos:\n",
    "    df2 = pd.read_csv(archivo)\n",
    "    df2[\"date\"] = transform_unix_to_utc(df2[\"utb_ms\"])\n",
    "    df = df.append(df2)\n",
    "  return df.head(1000)\n",
    "\n",
    "def replace_strings_with_int(series):\n",
    "    collection = list(set(series))\n",
    "    new_series = [collection.index(x)+1 for x in series]\n",
    "    return new_series\n",
    "\n",
    "def build_json_mars_express(lista_archivos):\n",
    "    all_jsons = []\n",
    "    for archivo in lista_archivos:\n",
    "        df = pd.read_csv(archivo).head(1000)\n",
    "        for col, row in df.iterrows():\n",
    "            new_json = dict({\"time\":\"\", \"measurament\":\"\", \"tags\":{\"satellite\":\"Mars Express\", \"decoder\":\"\", \"station\":\"\", \"observer\":\"\", \"source\":\"\", \"version\":\"\"}, \"fields\":{}})\n",
    "            new_json[\"time\"] = str(datetime.utcfromtimestamp(row[\"ut_ms\"]/1000))\n",
    "            new_json[\"fields\"] = dict(row)\n",
    "            all_jsons.append(new_json)\n",
    "    fp = open('decoded_frames.json', 'w')\n",
    "    fp.write(json.dumps(all_jsons, indent=3))\n",
    "    fp.close()\n",
    "    \n",
    "        \n",
    "def read_from_csv_mars_express(lista_archivos):\n",
    "\n",
    "  lista_archivos_saaf = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"saaf\"]\n",
    "  lista_archivos_dmop = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"dmop\"]\n",
    "  lista_archivos_ftl = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"ftl\"]\n",
    "  lista_archivos_evtf = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"evtf\"]\n",
    "  lista_archivos_ltdata = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"ltdata\"]\n",
    "\n",
    "  df_saaf = read_from_ut_ms(lista_archivos_saaf).drop(\"ut_ms\", axis=1)\n",
    "  df_dmop = read_from_ut_ms(lista_archivos_dmop).drop(\"ut_ms\", axis=1)\n",
    "  df_ftl = read_from_utb_ms(lista_archivos_ftl)\n",
    "  df_evtf = read_from_ut_ms(lista_archivos_evtf).drop(\"ut_ms\", axis=1)\n",
    "  df_ltdata = read_from_ut_ms(lista_archivos_ltdata).drop(\"ut_ms\", axis=1)\n",
    "    \n",
    "        \n",
    "  df = df_saaf\n",
    "  df = df.join(df_dmop.set_index(\"date\"), on=\"date\", how=\"outer\")\n",
    "  df = df.join(df_ftl.set_index(\"date\"), on=\"date\", how=\"outer\")\n",
    "  df = df.join(df_evtf.set_index(\"date\"), on=\"date\", how=\"outer\")\n",
    "  df = df.join(df_ltdata.set_index(\"date\"), on=\"date\", how=\"outer\").sort_values(\"date\")\n",
    "\n",
    "  df = df.fillna(0)\n",
    "\n",
    "  df[\"subsystem\"] = replace_strings_with_int(df[\"subsystem\"])\n",
    "  df[\"type\"] = replace_strings_with_int(df[\"type\"])\n",
    "  df[\"description\"] = replace_strings_with_int(df[\"description\"])\n",
    "  df[\"flagcomms\"] = replace_strings_with_int(df[\"flagcomms\"])\n",
    "\n",
    "  df = df.drop_duplicates()\n",
    "  return df\n",
    "\n",
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SE ALMACENAN LOS DATASETS EN JSONS\n",
    "lista_archivos_ltdata = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"ltdata\"]\n",
    "build_json_mars_express(lista_archivos_ltdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "#LECTURA DE LOS DATASETS DE MARS EXPRESS, Y DETECCIÓN DE OUTLIERS\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from limpieza_funciones import grafico_outliers\n",
    "\n",
    "\n",
    "def get_outliers(df):\n",
    "    # Limpieza de datos: detección de outliers.\n",
    "    outlier_method = EllipticEnvelope().fit(df)\n",
    "    scores_pred = outlier_method.decision_function(df)\n",
    "    \n",
    "    Q1 = stats.scoreatpercentile(scores_pred, 25)\n",
    "    Q3 = stats.scoreatpercentile(scores_pred, 75)\n",
    "    RIC = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5*RIC\n",
    "    limite_superior = Q3 + 1.5*RIC\n",
    "    \n",
    "    # Estimación de outliers\n",
    "    pos_i = np.where(scores_pred < limite_inferior)\n",
    "    pos_s = np.where(scores_pred > limite_superior)\n",
    "    \n",
    "    # Matriz de outliers\n",
    "    mask_outliers = np.ones(np.shape(scores_pred))\n",
    "    mask_outliers[pos_i] = 0\n",
    "    mask_outliers[pos_s] = 0\n",
    "    return mask_outliers\n",
    "\n",
    "def get_one_dataframe(lista_archivos):\n",
    "  columnas = []\n",
    "  for archivo in lista_archivos:\n",
    "    df1 = pd.read_csv(archivo)\n",
    "    columnas += list(df1.columns)\n",
    "    columnas = list(set(columnas))\n",
    "\n",
    "  df = pd.DataFrame(columns=columnas)\n",
    "  df = df.loc[:, ~df.columns.duplicated()]\n",
    "  for archivo in lista_archivos:\n",
    "    df2 = pd.read_csv(archivo)\n",
    "    df = df.append(df2)\n",
    "  return df.head(1000)\n",
    "\n",
    "\n",
    "def replace_strings_with_int(series):\n",
    "    collection = list(set(series))\n",
    "    new_series = [collection.index(x)+1 for x in series]\n",
    "    return new_series\n",
    "\n",
    "def check_csv_mars_express(lista_archivos):\n",
    "\n",
    "  lista_archivos_saaf = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"saaf\"]\n",
    "  lista_archivos_dmop = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"dmop\"]\n",
    "  lista_archivos_ftl = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"ftl\"]\n",
    "  lista_archivos_evtf = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"evtf\"]\n",
    "  lista_archivos_ltdata = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"ltdata\"]\n",
    "\n",
    "  #df_saaf = get_one_dataframe(lista_archivos_saaf)\n",
    "  #df_dmop = get_one_dataframe(lista_archivos_dmop) \n",
    "  #df_ftl = get_one_dataframe(lista_archivos_ftl)\n",
    "  #df_evtf = get_one_dataframe(lista_archivos_evtf)\n",
    "  df_ltdata = get_one_dataframe(lista_archivos_ltdata)\n",
    "    \n",
    "  #df_saaf_outliers = get_outliers(df_saaf)\n",
    "  #df_dmop_outliers = get_outliers(df_dmop) #no son valores numéricos\n",
    "  #df_ftl_outliers = get_outliers(df_ftl) #no son valores numéricos\n",
    "  #df_evtf_outliers = get_outliers(df_evtf) #no son valores numéricos\n",
    "  df_ltdata_outliers = get_outliers(df_ltdata)\n",
    "  print(df_ltdata_outliers[df_ltdata_outliers==0].shape)\n",
    " \n",
    "  return df_ltdata.iloc[df_ltdata_outliers==0]\n",
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (131.954708924444503 > 131.677245494658820). You may want to try with a higher value of support_fraction (current value: 0.505).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (131.285196108101331 > 131.174769744030897). You may want to try with a higher value of support_fraction (current value: 0.505).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (129.690530673069674 > 129.579318623563694). You may want to try with a higher value of support_fraction (current value: 0.505).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (126.820529116210039 > 126.774757538308478). You may want to try with a higher value of support_fraction (current value: 0.505).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (126.770404056198643 > 126.672383080176900). You may want to try with a higher value of support_fraction (current value: 0.505).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (126.611402802747477 > 126.590177556412399). You may want to try with a higher value of support_fraction (current value: 0.505).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177,)\n",
      "     solarconstantmars  earthmars_km  occultationduration_min  \\\n",
      "0           522.263999  3.557560e+08                27.400000   \n",
      "1           522.863537  3.563037e+08                26.933333   \n",
      "2           523.468926  3.568432e+08                26.583333   \n",
      "3           524.080161  3.573744e+08                26.100000   \n",
      "4           524.697233  3.578973e+08                25.750000   \n",
      "..                 ...           ...                      ...   \n",
      "172         682.000839  3.480923e+08                57.000000   \n",
      "173         682.872583  3.476735e+08                58.050000   \n",
      "174         683.736270  3.472537e+08                58.666667   \n",
      "175         684.591739  3.468329e+08                59.416667   \n",
      "176         685.438830  3.464111e+08                59.866667   \n",
      "\n",
      "     eclipseduration_min          ut_ms  sunmarsearthangle_deg    sunmars_km  \n",
      "0               4.166667  1219363200000              19.565076  2.419389e+08  \n",
      "1               1.783333  1219449600000              19.390075  2.418002e+08  \n",
      "2               0.000000  1219536000000              19.214734  2.416603e+08  \n",
      "3               0.000000  1219622400000              19.039052  2.415193e+08  \n",
      "4               0.000000  1219708800000              18.863029  2.413773e+08  \n",
      "..                   ...            ...                    ...           ...  \n",
      "172            30.683333  1234224000000              11.945563  2.117183e+08  \n",
      "173            33.800000  1234310400000              12.115930  2.115831e+08  \n",
      "174            35.850000  1234396800000              12.285935  2.114494e+08  \n",
      "175            38.250000  1234483200000              12.455583  2.113172e+08  \n",
      "176            39.866667  1234569600000              12.624872  2.111866e+08  \n",
      "\n",
      "[177 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (126.540589719945345 > 126.468694477382442). You may want to try with a higher value of support_fraction (current value: 0.505).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.425024179372116 > 128.206535048725669). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.542986081495741 > 128.438396141928422). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.555296926107417 > 128.397280391955462). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.488460541735435 > 128.245080967017998). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.587976216129817 > 128.548090043836169). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.591996011458008 > 128.527926077334314). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.599212546324964 > 128.524878588357296). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.638093405383927 > 128.588862708652471). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.623339522130266 > 128.528430792639028). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.151638030620859 > 127.987225803616028). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.796633556337980 > 127.601786215173519). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.239706748194095 > 128.011579774485824). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.335554074629442 > 128.248033286199529). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.953205301965113 > 127.676286788241569). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.222424578722155 > 127.886284184520918). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.338659675030357 > 128.135086778925512). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.097505247118136 > 128.007234275543794). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.211960797104325 > 127.831684620032448). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (128.343388612925537 > 128.288118503181863). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.831536852881314 > 127.674412932557075). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.331358409056975 > 127.309388517049570). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.336355420351040 > 127.304427244690146). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.380354618674318 > 127.339799126268503). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.638453163581687 > 127.585762339654593). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.700171695464434 > 127.619481765962846). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.508381442591755 > 127.381410939917799). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.474038033543891 > 127.377892053862126). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n",
      "C:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:166: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (127.805020051327517 > 127.797334567084064). You may want to try with a higher value of support_fraction (current value: 0.504).\n",
      "  warnings.warn(\"Determinant has increased; this should not happen: \"\n"
     ]
    }
   ],
   "source": [
    "#COMPROBAR RESULTADOS ANTES DE UTILIZAR POLARIS\n",
    "outs = check_csv_mars_express(lista_archivos_marsexpress)\n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#COMPROBAR RESULTADOS ANTES DE UTILIZAR POLARIS\n",
    "df = read_from_txt_lightsail(lista_archivos_lightsail)\n",
    "display(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "sbj0GWnPysEc",
    "outputId": "d85f37dd-bb2e-4ea3-86e1-7ac722e64309"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sz</th>\n",
       "      <th>sa</th>\n",
       "      <th>sx</th>\n",
       "      <th>sy</th>\n",
       "      <th>date</th>\n",
       "      <th>subsystem</th>\n",
       "      <th>utb_ms</th>\n",
       "      <th>ute_ms</th>\n",
       "      <th>type</th>\n",
       "      <th>flagcomms</th>\n",
       "      <th>description</th>\n",
       "      <th>sunmars_km</th>\n",
       "      <th>eclipseduration_min</th>\n",
       "      <th>solarconstantmars</th>\n",
       "      <th>sunmarsearthangle_deg</th>\n",
       "      <th>earthmars_km</th>\n",
       "      <th>occultationduration_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:00</td>\n",
       "      <td>75</td>\n",
       "      <td>1219363213000</td>\n",
       "      <td>1219365494000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.419389e+08</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>522.263999</td>\n",
       "      <td>19.565076</td>\n",
       "      <td>3.557560e+08</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>475</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:28</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:28</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:28</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:28</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:38</td>\n",
       "      <td>1</td>\n",
       "      <td>1219365494000</td>\n",
       "      <td>1219369555000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:40</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:47</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 00:57</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:09</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>432</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:37</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:39</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:41</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:41</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:41</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:41</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:44</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:44</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-22 01:44</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sz   sa   sx   sy              date  subsystem         utb_ms  \\\n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:00         75  1219363213000   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:17          1              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:19          1              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:28         31              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:28         32              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:28         47              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:28         68              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:30          1              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:38          1  1219365494000   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:40         15              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:42          1              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:47         95              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 00:57        122              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:05          1              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:09         12              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:30          1              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:37         64              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:39        110              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:41         34              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:41        159              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:41        133              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:41        160              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:44         80              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:44         45              0   \n",
       "NaN  0.0  0.0  0.0  0.0  2008-08-22 01:44        175              0   \n",
       "\n",
       "            ute_ms  type  flagcomms  description    sunmars_km  \\\n",
       "NaN  1219365494000     6          1            1  2.419389e+08   \n",
       "NaN              0     1          1          475  0.000000e+00   \n",
       "NaN              0     1          1           95  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1          283  0.000000e+00   \n",
       "NaN  1219369555000     6          2            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1           56  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1          153  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1          432  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1           58  0.000000e+00   \n",
       "NaN              0     1          1           58  0.000000e+00   \n",
       "NaN              0     1          1           58  0.000000e+00   \n",
       "NaN              0     1          1           58  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "NaN              0     1          1            1  0.000000e+00   \n",
       "\n",
       "     eclipseduration_min  solarconstantmars  sunmarsearthangle_deg  \\\n",
       "NaN             4.166667         522.263999              19.565076   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "NaN             0.000000           0.000000               0.000000   \n",
       "\n",
       "     earthmars_km  occultationduration_min  \n",
       "NaN  3.557560e+08                     27.4  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  \n",
       "NaN  0.000000e+00                      0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#COMPROBAR RESULTADOS ANTES DE UTILIZAR POLARIS\n",
    "df = read_from_csv_mars_express(lista_archivos_marsexpress)\n",
    "display(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df.head(25))\n",
    "print(\"subsystem: \", len(set(df[\"subsystem\"])),len(df[\"subsystem\"]))\n",
    "print(\"type: \", len(set(df[\"type\"])),len(df[\"type\"]))\n",
    "print(\"description: \", len(set(df[\"description\"])),len(df[\"description\"]))\n",
    "print(\"flagcomms: \", len(set(df[\"flagcomms\"])),len(df[\"flagcomms\"]), set(df[\"flagcomms\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmpHtEkGWJuH",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#datatest1 = pd.DataFrame({\"Nombre\": [\"Daenerys\", \"Deku\", \"Bakugo\", \"Peter Pan\", \"Akamatsu\", \"Spiderman\", \"Joey Mills\"], \"Serie\": [\"Juego de Tronos\", \"BNHA\", \"BNHA\", \"Peter Pan\", \"Akamatsu y Seven\", \"Spiderman\", \"Helix Studios\"], \"Me gusta\": [\"True\", \"True\", \"True\", \"False\", \"True\", \"True\", \"Supertrue\"]})\n",
    "#datatest2 = pd.DataFrame({\"Nombre\": [\"Davos\", \"Homer\", \"Joey\", \"Jay\", \"Seven\", \"Loki\", \"Blake Mitchell\"], \"Serie\": [\"Juego de Tronos\", \"Simpsons\", \"Friends\", \"Modern Family\", \"Akamatsu y Seven\", \"Loki\", \"Helix Studios\"], \"Me gusta\": [\"False\", \"True\", \"True\", \"False\", \"True\", \"True\", \"True\"]})\n",
    "#datatest3 = pd.DataFrame({\"Nombre\": [\"Arya\", \"Peter\", \"Ted\", \"Gloria\", \"El primo violador\", \"Wanda\", \"Steven Prior\"], \"Serie\": [\"Juego de Tronos\", \"Padre de Familia\", \"HIMYM\", \"Modern Family\", \"Akamatsu y Seven\", \"Wandavision\", \"Tim Tales\"], \"Me gusta\": [\"True\", \"False\", \"False\", \"True\", \"False\", \"True\", \"True\"]})\n",
    "\n",
    "\n",
    "\n",
    "datatest1 = pd.DataFrame({\"Fecha\": [\"07/01/2022\", \"08/01/2022\", \"09/01/2022\", \"10/01/2022\", \"11/01/2022\"],\n",
    "                          \"Clima en Elche\": [\"Soleado\", \"Nublado\", \"Niebla\", \"Nublado\", \"Lluvioso\"]})\n",
    "\n",
    "datatest2 = pd.DataFrame({\"Fecha\": [\"07/01/2022\", \"08/01/2022\", \"09/01/2022\", \"10/01/2022\", \"11/01/2022\"],\n",
    "                          \"Noticia del día\": [\"Secuestran a peter\", \"Vuelve el volcán de la palma\", \"Cancelan a Energuia\", \"Memes de Jordi Wild\", \"Sube la luz\"]})\n",
    "\n",
    "datatest3 = pd.DataFrame({\"Fecha\": [\"07/01/2022\", \"08/01/2022\", \"09/01/2022\", \"10/01/2022\", \"11/01/2022\", \"12/10/2022\"],\n",
    "                          \"Gasolina de mi coche\": [\"Nada\", \"Mucha\", \"Mucha\", \"Media\", \"Poca\", \"Muy Poca\"],\n",
    "                          \"Precio del pan\": [0.5, 0.5, 0.5, 0.6, 0.6, 0.9]})\n",
    "\n",
    "df = datatest1\n",
    "df = df.join(datatest2.set_index(\"Fecha\"), on=\"Fecha\", how=\"outer\")\n",
    "df = df.join(datatest3.set_index(\"Fecha\"), on=\"Fecha\", how=\"outer\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzPPwEj0jM29",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GUARDAR CSV DEL LIGHTSAIL2 PARA PROCESAMIENTO DE POLARIS\n",
    "df_csv = df.to_csv('lightsail_dataset.csv', sep=',', index=False)\n",
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "benZjPIheBK1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "#GUARDAR CSV DEL MARS EXPRESS PARA PROCESAMIENTO DE POLARIS\n",
    "df_csv = df.to_csv('marsexpress_dataset.csv', sep=',', index=False)\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CLEANER.PY DE POLARIS, PARA PODER PERSONALIZARLO SEGÚN EL DATASET CONVENGA\n",
    "\n",
    "\"\"\"Module for cleaning data\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# pylint: disable=R0903\n",
    "class Cleaner:\n",
    "    \"\"\"Class for cleaning features.\n",
    "    \"\"\"\n",
    "    def __init__(self, metadata, cleaning_params):\n",
    "        # in percent, maximum na rows in a column\n",
    "        self._col_threshold = cleaning_params.col_max_na_percentage\n",
    "        # in percent, maximum na columns in a row\n",
    "        self._row_threshold = cleaning_params.row_max_na_percentage\n",
    "        self._metadata = metadata\n",
    "\n",
    "    def handle_missing_values(self, dataframe):\n",
    "        \"\"\"Preprocess data to remove unnecessary rows and columns (filled with\n",
    "        nan)\n",
    "\n",
    "        :param dataframe: Dataframe that needs to be preprocessed\n",
    "        :type dataframe: pd.DataFrame\n",
    "        :return: Preprocessed Dataframe\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        initial_shape = dataframe.shape\n",
    "\n",
    "        # Dropping columns first so that frames without necessary columns\n",
    "        # of data are removed.\n",
    "        # Remove columns not satisfying criteria\n",
    "        count_na_col = dataframe.isna().sum()\n",
    "        count_na_col = count_na_col * (100 / dataframe.shape[0])\n",
    "        dataframe = dataframe.loc[:, count_na_col < self._col_threshold]\n",
    "\n",
    "        # Remove rows not satisfying criteria\n",
    "        count_na_row = dataframe.isna().sum(axis=1)\n",
    "        if dataframe.shape[1] != 0:\n",
    "            count_na_row = count_na_row * (100 / dataframe.shape[1])\n",
    "        else:\n",
    "            count_na_row = 0\n",
    "\n",
    "        dataframe = dataframe.loc[count_na_row < self._row_threshold, :]\n",
    "\n",
    "        # ffill will fill all but the first set of nans\n",
    "        # bfill will fill the first set of nans\n",
    "        # (if nans are present in the first few rows)\n",
    "        # Fill nans with nearest value\n",
    "        dataframe = dataframe.fillna(method=\"ffill\")\n",
    "        dataframe = dataframe.fillna(method=\"bfill\")\n",
    "\n",
    "        final_shape = dataframe.shape\n",
    "\n",
    "        LOGGER.debug(\"Initial Shape: %s, Final Shape: %s\", initial_shape,\n",
    "                     final_shape)\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    def drop_constant_values(self, dataframe):\n",
    "        \"\"\"Preprocess data to remove columns with\n",
    "        constant values\n",
    "\n",
    "        :param dataframe: Dataframe that needs to be preprocessed\n",
    "        :type dataframe: pd.DataFrame\n",
    "        :return: Preprocessed Dataframe\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if 'analysis' in self._metadata:\n",
    "            constants = [\n",
    "                column for column, tag in self._metadata['analysis']\n",
    "                ['column_tags'].items() if tag == \"constant\"\n",
    "            ]\n",
    "\n",
    "            LOGGER.info('Dropping constant column(s) : %s',\n",
    "                        ','.join(constants))\n",
    "\n",
    "            return dataframe.drop(constants, axis=1)\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_non_numeric_values(dataframe):\n",
    "        \"\"\"Preprocess data to remove non numeric columns\n",
    "\n",
    "        :param dataframe: Dataframe that needs to be preprocessed\n",
    "        :type dataframe: pd.DataFrame\n",
    "        :return: Preprocessed Dataframe\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        return dataframe.select_dtypes(include=['number', 'datetime'])\n",
    "\n",
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CROSS_CORRELATION.PY DE POLARIS, PARA PODER PERSONALIZARLO SEGÚN EL DATASET CONVENGA\n",
    "\"\"\"\n",
    "Cross Correlation module\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import enlighten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Used for tracking ML process results\n",
    "from mlflow import log_metric, log_param, log_params, start_run\n",
    "# Used for the pipeline interface of scikit learn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "# eXtreme Gradient Boost algorithm\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Remove this line when feature engineering is in place\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "\n",
    "class XCorr(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Cross Correlation predictor class\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_metadata, cross_correlation_params):\n",
    "        \"\"\" Initialize an XCorr object\n",
    "\n",
    "            :param dataset_metadata: The metadata of the dataset\n",
    "            :type dataset_metadata: PolarisMetadata\n",
    "            :param cross_correlation_params: XCorr parameters\n",
    "            :type cross_correlation_params: CrossCorrelationParameters\n",
    "        \"\"\"\n",
    "        self.models = None\n",
    "        self._importances_map = None\n",
    "        self._feature_cleaner = Cleaner(\n",
    "            dataset_metadata, cross_correlation_params.dataset_cleaning_params)\n",
    "        self.xcorr_params = {\n",
    "            \"random_state\": cross_correlation_params.random_state,\n",
    "            \"test_size\": cross_correlation_params.test_size,\n",
    "            \"gridsearch_scoring\": cross_correlation_params.gridsearch_scoring,\n",
    "            \"gridsearch_n_splits\":\n",
    "            cross_correlation_params.gridsearch_n_splits,\n",
    "        }\n",
    "        # If we're importing from CSV, the dataset_metadata may not\n",
    "        # have the feature_columns key.\n",
    "        try:\n",
    "            self.xcorr_params['feature_columns'] = dataset_metadata[\n",
    "                'analysis']['feature_columns']\n",
    "        except KeyError:\n",
    "            LOGGER.info(\n",
    "                \"No feature_columns entry in metatdata, setting to empty array\"\n",
    "            )\n",
    "            self.xcorr_params['feature_columns'] = []\n",
    "\n",
    "        if cross_correlation_params.use_gridsearch:\n",
    "            self.method = self.gridsearch\n",
    "            self.mlf_logging = self.gridsearch_mlf_logging\n",
    "        else:\n",
    "            self.method = self.regression\n",
    "            self.mlf_logging = self.regression_mlf_logging\n",
    "\n",
    "        self.model_params = {\n",
    "            \"current\": cross_correlation_params.model_params,\n",
    "            \"cpu\": cross_correlation_params.model_cpu_params\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def importances_map(self):\n",
    "        \"\"\"\n",
    "        Return the importances_map value as Pandas Dataframe.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        return self._importances_map\n",
    "\n",
    "    @importances_map.setter\n",
    "    def importances_map(self, importances_map):\n",
    "        self._importances_map = importances_map\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\" Train on a dataframe\n",
    "\n",
    "            The input dataframe will be split column by column\n",
    "            considering each one as a prediction target.\n",
    "\n",
    "            :param X: Input dataframe\n",
    "            :type X: pd.DataFrame\n",
    "            :raises Exception: If encountered any unhandled error\n",
    "                during model fitting\n",
    "        \"\"\"\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"Input data should be a DataFrame\")\n",
    "\n",
    "        if self.models is None:\n",
    "            self.models = []\n",
    "\n",
    "        manager = enlighten.get_manager()\n",
    "\n",
    "        LOGGER.info(\"Clearing Data. Removing unnecessary columns\")\n",
    "        X = self._feature_cleaner.drop_constant_values(X)\n",
    "        X = self._feature_cleaner.drop_non_numeric_values(X)\n",
    "        X = self._feature_cleaner.handle_missing_values(X)\n",
    "\n",
    "        self.reset_importance_map(X.columns)\n",
    "\n",
    "        parameters = self.__build_parameters(X)\n",
    "\n",
    "        pbar = manager.counter(total=len(parameters),\n",
    "                               desc=\"Columns\",\n",
    "                               unit=\"columns\")\n",
    "\n",
    "        with start_run(run_name='cross_correlate', nested=True):\n",
    "            self.mlf_logging()\n",
    "            for column in parameters:\n",
    "                LOGGER.info(column)\n",
    "                try:\n",
    "                    self.models.append(\n",
    "                        self.method(X.drop([column], axis=1), X[column],\n",
    "                                    self.model_params['current']))\n",
    "                except Exception as err:  # pylint: disable-msg=broad-except\n",
    "                    if self.model_params['current'].get(\n",
    "                            \"predictor\") == \"gpu_predictor\":\n",
    "                        LOGGER.info(\" \".join([\n",
    "                            \"Encountered error using GPU.\",\n",
    "                            \"Trying with CPU parameters now!\"\n",
    "                        ]))\n",
    "                        self.model_params['current'] = self.model_params['cpu']\n",
    "                    else:\n",
    "                        raise err\n",
    "                pbar.update()\n",
    "\n",
    "    def transform(self):\n",
    "        \"\"\" Unused method in this predictor \"\"\"\n",
    "        return self\n",
    "\n",
    "    def regression(self, df_in, target_series, model_params):\n",
    "        \"\"\" Fit a model to predict target_series with df_in features/columns\n",
    "            and retain the features importances in the dependency matrix.\n",
    "\n",
    "            :param df_in: Input dataframe representing the context, predictors\n",
    "            :type df_in: pd.DataFrame\n",
    "            :param target_series: pandas series of the target variable. Share\n",
    "                the same indexes as the df_in dataframe\n",
    "            :type target_series: pd.Series\n",
    "            :param model_params: Parameters for the XGB model\n",
    "            :type model_params: dict\n",
    "            :return: A fitted XGBRegressor\n",
    "            :rtype: XGBRegressor\n",
    "        \"\"\"\n",
    "        # Split df_in and target to train and test dataset\n",
    "        df_in_train, df_in_test, target_train, target_test = train_test_split(\n",
    "            df_in,\n",
    "            target_series,\n",
    "            test_size=0.2,\n",
    "            random_state=self.xcorr_params['random_state'])\n",
    "\n",
    "        # Create and train a XGBoost regressor\n",
    "        regr_m = XGBRegressor(**model_params)\n",
    "        regr_m.fit(df_in_train, target_train)\n",
    "\n",
    "        # Make predictions\n",
    "        target_series_predict = regr_m.predict(df_in_test)\n",
    "\n",
    "        try:\n",
    "            rmse = np.sqrt(\n",
    "                mean_squared_error(target_test, target_series_predict))\n",
    "            log_metric(target_series.name, rmse)\n",
    "            LOGGER.info('Making predictions for : %s', target_series.name)\n",
    "            LOGGER.info('Root Mean Square Error : %s', str(rmse))\n",
    "        except Exception:  # pylint: disable-msg=broad-except\n",
    "            # Because of large (close to infinite values) or nans\n",
    "            LOGGER.error('Cannot find RMS Error for %s', target_series.name)\n",
    "            LOGGER.debug('Expected %s, Predicted %s', str(target_test),\n",
    "                         str(target_series_predict))\n",
    "\n",
    "        # indices = np.argsort(regr_m.feature_importances_)[::-1]\n",
    "        # After the model is trained\n",
    "        new_row = {}\n",
    "        for column, feat_imp in zip(df_in.columns,\n",
    "                                    regr_m.feature_importances_):\n",
    "            new_row[column] = [feat_imp]\n",
    "\n",
    "        # Current target is not in df_in, so manually adding it\n",
    "        new_row[target_series.name] = [0.0]\n",
    "\n",
    "        # Sorting new_row to avoid concatenation warnings\n",
    "        new_row = dict(sorted(new_row.items()))\n",
    "\n",
    "        # Concatenating new information about feature importances\n",
    "        if self._importances_map is not None:\n",
    "            self._importances_map = pd.concat([\n",
    "                self._importances_map,\n",
    "                pd.DataFrame(index=[target_series.name], data=new_row)\n",
    "            ])\n",
    "        return regr_m\n",
    "\n",
    "    def gridsearch(self, df_in, target_series, params):\n",
    "        \"\"\" Apply grid search to fine-tune XGBoost hyperparameters\n",
    "            and then call the regression method with the best grid\n",
    "            search parameters.\n",
    "\n",
    "            :param df_in: Input dataframe representing the context, predictors\n",
    "            :type df_in: pd.DataFrame\n",
    "            :param target_series: Pandas series of the target variable. Share\n",
    "                the same indexes as the df_in dataframe\n",
    "            :type target_series: pd.Series\n",
    "            :param params: The hyperparameters to use on the gridsearch\n",
    "                method\n",
    "            :type params: dict\n",
    "            :raises TypeError: If df_in is not Pandas DataFrame\n",
    "            :return: A fitted XGBRegressor\n",
    "            :rtype: XGBRegressor\n",
    "        \"\"\"\n",
    "        if not isinstance(df_in, pd.DataFrame):\n",
    "            LOGGER.error(\"Expected %s got %s for df_in in gridsearch\",\n",
    "                         pd.DataFrame, type(df_in))\n",
    "            raise TypeError\n",
    "\n",
    "        random_state = self.xcorr_params['random_state']\n",
    "        kfolds = KFold(n_splits=self.xcorr_params['gridsearch_n_splits'],\n",
    "                       shuffle=True,\n",
    "                       random_state=random_state)\n",
    "        regr_m = XGBRegressor(random_state=random_state,\n",
    "                              predictor=\"cpu_predictor\",\n",
    "                              tree_method=\"auto\",\n",
    "                              n_jobs=-1)\n",
    "\n",
    "        gs_regr = GridSearchCV(regr_m,\n",
    "                               param_grid=params,\n",
    "                               cv=kfolds,\n",
    "                               scoring=self.xcorr_params['gridsearch_scoring'],\n",
    "                               n_jobs=-1,\n",
    "                               verbose=1)\n",
    "        gs_regr.fit(df_in, target_series)\n",
    "\n",
    "        log_param(target_series.name + ' best estimator', gs_regr.best_params_)\n",
    "        LOGGER.info(\"%s best estimator : %s\", target_series.name,\n",
    "                    str(gs_regr.best_estimator_))\n",
    "        return self.regression(df_in, target_series, gs_regr.best_params_)\n",
    "\n",
    "    def reset_importance_map(self, columns):\n",
    "        \"\"\"\n",
    "        Creating an empty importance map\n",
    "\n",
    "        :param columns: List of column names for the importance map\n",
    "        :rtype columns: pd.Index or array-like\n",
    "        \"\"\"\n",
    "        if self._importances_map is None:\n",
    "            self._importances_map = pd.DataFrame(data={}, columns=columns)\n",
    "\n",
    "    def common_mlf_logging(self):\n",
    "        \"\"\" Log the parameters used for gridsearch and regression\n",
    "            in mlflow\n",
    "        \"\"\"\n",
    "        log_param('Test size', self.xcorr_params['test_size'])\n",
    "        log_param('Model', 'XGBRegressor')\n",
    "\n",
    "    def gridsearch_mlf_logging(self):\n",
    "        \"\"\" Log the parameters used for gridsearch\n",
    "            in mlflow\n",
    "        \"\"\"\n",
    "        log_param('Gridsearch scoring',\n",
    "                  self.xcorr_params['gridsearch_scoring'])\n",
    "        log_param('Gridsearch parameters', self.model_params)\n",
    "        self.common_mlf_logging()\n",
    "\n",
    "    def regression_mlf_logging(self):\n",
    "        \"\"\" Log the parameters used for regression\n",
    "            in mlflow.\n",
    "        \"\"\"\n",
    "        self.common_mlf_logging()\n",
    "        log_params(self.model_params)\n",
    "\n",
    "    def __build_parameters(self, X):\n",
    "        \"\"\" Remove features only from\n",
    "            being predicted.\n",
    "\n",
    "            :param X: The dataset\n",
    "            :type X: pd.DataFrame\n",
    "            :return: List of remaining features that are not removed\n",
    "            :rtype: list\n",
    "        \"\"\"\n",
    "        if self.xcorr_params['feature_columns'] is None:\n",
    "            return list(X.columns)\n",
    "\n",
    "        LOGGER.info('Removing features from the parameters : %s',\n",
    "                    self.xcorr_params['feature_columns'])\n",
    "        feature_to_remove = set(self.xcorr_params['feature_columns'])\n",
    "\n",
    "        return [x for x in list(X.columns) if x not in feature_to_remove]\n",
    "\n",
    "\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "PoDmNLQib2tg",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "#ANALISYS.PY DE POLARIS, PARA PODER PERSONALIZARLO SEGÚN EL DATASET CONVENGA\n",
    "\n",
    "\"\"\"\n",
    "Module to launch different data analysis.\n",
    "\"\"\"\n",
    "import logging\n",
    "from fets.math import TSIntegrale\n",
    "from mlflow import set_experiment\n",
    "\n",
    "from polaris.data.graph import PolarisGraph\n",
    "from polaris.data.readers import read_polaris_data\n",
    "from polaris.dataset.metadata import PolarisMetadata\n",
    "from polaris.learn.feature.extraction import create_list_of_transformers, \\\n",
    "    extract_best_features\n",
    "from polaris.learn.predictor.cross_correlation_configurator import \\\n",
    "    CrossCorrelationConfigurator\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class NoFramesInInputFile(Exception):\n",
    "    \"\"\"Raised when frames dataframe is empty\"\"\"\n",
    "\n",
    "\n",
    "def feature_extraction(input_file, param_col):\n",
    "    \"\"\"\n",
    "    Start feature extraction using the given settings.\n",
    "\n",
    "        :param input_file: Path of a CSV file that will be\n",
    "            converted to a dataframe\n",
    "        :type input_file: str\n",
    "        :param param_col: Target column name\n",
    "        :type param_col: str\n",
    "    \"\"\"\n",
    "    # Create a small list of two transformers which will generate two\n",
    "    # different pipelines\n",
    "    transformers = create_list_of_transformers([\"5min\", \"15min\"], TSIntegrale)\n",
    "\n",
    "    # Extract the best features of the two pipelines\n",
    "    out = extract_best_features(input_file,\n",
    "                                transformers,\n",
    "                                target_column=param_col,\n",
    "                                time_unit=\"ms\")\n",
    "\n",
    "    # out[0] is the FeatureImportanceOptimization object\n",
    "    # from polaris.learn.feature.selection\n",
    "    # pylint: disable=E1101\n",
    "    print(out[0].best_features)\n",
    "\n",
    "\n",
    "# pylint: disable-msg=too-many-arguments\n",
    "def cross_correlate(input_file,\n",
    "                    output_graph_file=None,\n",
    "                    xcorr_configuration_file=None,\n",
    "                    graph_link_threshold=0.1,\n",
    "                    use_gridsearch=False,\n",
    "                    csv_sep=',',\n",
    "                    force_cpu=False):\n",
    "    \"\"\"\n",
    "    Catch linear and non-linear correlations between all columns of the\n",
    "    input data.\n",
    "\n",
    "        :param input_file: CSV or JSON file path that will be\n",
    "            converted to a dataframe\n",
    "        :type input_file: str\n",
    "        :param output_graph_file: Output file path for the generated graph.\n",
    "            It will overwrite if the file already exists. Defaults to None,\n",
    "            which is'/tmp/polaris_graph.json'\n",
    "        :type output_graph_file: str, optional\n",
    "        :param xcorr_configuration_file: XCorr configuration file path,\n",
    "            defaults to None. Refer to CrossCorrelationConfigurator for\n",
    "            the default parameters\n",
    "        :type xcorr_configuration_file: str, optional\n",
    "        :param graph_link_threshold: Minimum link value to be considered\n",
    "            as a link between two nodes\n",
    "        :type graph_link_threshold: float, optional\n",
    "        :param use_gridsearch: Use grid search for the cross correlation.\n",
    "            If this is set to False, then it will just use regression.\n",
    "            Defaults to False\n",
    "        :type use_gridsearch: bool, optional\n",
    "        :param csv_sep: The character that separates the columns inside of\n",
    "            the CSV file, defaults to ','\n",
    "        :type csv_sep: str, optional\n",
    "        :param force_cpu: Force CPU for cross corelation, defaults to False\n",
    "        :type force_cpu: bool, optional\n",
    "        :raises NoFramesInInputFile: If there are no frames in the converted\n",
    "            dataframe\n",
    "    \"\"\"\n",
    "    # Reading input file - index is considered on first column\n",
    "    metadata, dataframe = read_polaris_data(input_file, csv_sep)\n",
    "\n",
    "    if dataframe.empty:\n",
    "        LOGGER.error(\"Empty list of frames -- nothing to learn from!\")\n",
    "        raise NoFramesInInputFile\n",
    "\n",
    "    input_data = normalize_dataframe(dataframe)\n",
    "    source = metadata['satellite_name']\n",
    "\n",
    "    set_experiment(experiment_name=source)\n",
    "\n",
    "    xcorr_configurator = CrossCorrelationConfigurator(\n",
    "        xcorr_configuration_file=xcorr_configuration_file,\n",
    "        use_gridsearch=use_gridsearch,\n",
    "        force_cpu=force_cpu)\n",
    "\n",
    "    # Creating and fitting cross-correlator\n",
    "    xcorr = XCorr(metadata, xcorr_configurator.get_configuration())\n",
    "    xcorr.fit(input_data)\n",
    "\n",
    "    if output_graph_file is None:\n",
    "        output_graph_file = \"/tmp/polaris_graph.json\"\n",
    "\n",
    "    metadata = PolarisMetadata({\"satellite_name\": source})\n",
    "    graph = PolarisGraph(metadata=metadata)\n",
    "    graph.from_heatmap(xcorr.importances_map, graph_link_threshold)\n",
    "    with open(output_graph_file, 'w') as graph_file:\n",
    "        graph_file.write(graph.to_json())\n",
    "\n",
    "\n",
    "def normalize_dataframe(dataframe):\n",
    "    \"\"\"\n",
    "        Apply dataframe modification so it's compatible\n",
    "        with the learn module. The time column is first\n",
    "        set as the index of the dataframe. Then, we drop\n",
    "        the time column.\n",
    "\n",
    "        :param dataframe: The pandas dataframe to normalize\n",
    "        :type dataframe: pd.DataFrame\n",
    "        :return: Pandas dataframe normalized\n",
    "        :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    #PARA MARS EXPRESS\n",
    "    dataframe.index = dataframe.date\n",
    "    dataframe.drop(['date'], axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "    #PARA LIGHTSAIL2\n",
    "    #return dataframe\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SLFiMJXiTeY",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GENERA EL GRAFO DE LIGHTSAIL2\n",
    "cross_correlate(\"lightsail_dataset.csv\")\n",
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "Z0vAEqPbePhd",
    "outputId": "e727f3c9-9867-4397-e0fb-df8332c47a33"
   },
   "outputs": [],
   "source": [
    "#GENERA EL GRAFO DE MARS EXPRESS\n",
    "cross_correlate(\"marsexpress_dataset.csv\")\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2012-05-27 00:16\n",
       "3    2012-05-27 00:28\n",
       "4    2012-05-27 00:29\n",
       "Name: date, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[\"date\"][2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.24730430e+02 1.58943900e+01 4.27452900e+01 ... 1.95650758e+01\n",
      "  3.55756044e+08 2.74000000e+01]\n",
      " [1.24730430e+02 1.58943900e+01 4.27452900e+01 ... 2.09137752e+01\n",
      "  2.84165803e+08 3.53781307e+01]\n",
      " [1.24730430e+02 1.58943900e+01 4.27452900e+01 ... 2.09137752e+01\n",
      "  2.84165803e+08 3.53781307e+01]\n",
      " ...\n",
      " [1.34750000e+02 1.49600000e+01 4.85700000e+01 ... 2.09137752e+01\n",
      "  2.84165803e+08 3.53781307e+01]\n",
      " [1.35530000e+02 1.39900000e+01 4.88500000e+01 ... 2.09137752e+01\n",
      "  2.84165803e+08 3.53781307e+01]\n",
      " [1.34900000e+02 1.49000000e+01 4.86100000e+01 ... 2.09137752e+01\n",
      "  2.84165803e+08 3.53781307e+01]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sz</th>\n",
       "      <th>sa</th>\n",
       "      <th>sx</th>\n",
       "      <th>sy</th>\n",
       "      <th>subsystem</th>\n",
       "      <th>utb_ms</th>\n",
       "      <th>ute_ms</th>\n",
       "      <th>type</th>\n",
       "      <th>flagcomms</th>\n",
       "      <th>description</th>\n",
       "      <th>sunmars_km</th>\n",
       "      <th>eclipseduration_min</th>\n",
       "      <th>solarconstantmars</th>\n",
       "      <th>sunmarsearthangle_deg</th>\n",
       "      <th>earthmars_km</th>\n",
       "      <th>occultationduration_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1219363213000</td>\n",
       "      <td>1219365494000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.419389e+08</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>522.263999</td>\n",
       "      <td>19.565076</td>\n",
       "      <td>3.557560e+08</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>475</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1219365494000</td>\n",
       "      <td>1219369555000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>432</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sz   sa   sx   sy  subsystem         utb_ms         ute_ms  type  \\\n",
       "NaN  0.0  0.0  0.0  0.0         75  1219363213000  1219365494000     6   \n",
       "NaN  0.0  0.0  0.0  0.0          1              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0          1              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         31              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         32              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         47              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         68              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0          1              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0          1  1219365494000  1219369555000     6   \n",
       "NaN  0.0  0.0  0.0  0.0         15              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0          1              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         95              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0        122              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0          1              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         12              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0          1              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         64              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0        110              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         34              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0        159              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0        133              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0        160              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         80              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0         45              0              0     1   \n",
       "NaN  0.0  0.0  0.0  0.0        175              0              0     1   \n",
       "\n",
       "     flagcomms  description    sunmars_km  eclipseduration_min  \\\n",
       "NaN          1            1  2.419389e+08             4.166667   \n",
       "NaN          1          475  0.000000e+00             0.000000   \n",
       "NaN          1           95  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1          283  0.000000e+00             0.000000   \n",
       "NaN          2            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1           56  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1          153  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1          432  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1           58  0.000000e+00             0.000000   \n",
       "NaN          1           58  0.000000e+00             0.000000   \n",
       "NaN          1           58  0.000000e+00             0.000000   \n",
       "NaN          1           58  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "NaN          1            1  0.000000e+00             0.000000   \n",
       "\n",
       "     solarconstantmars  sunmarsearthangle_deg  earthmars_km  \\\n",
       "NaN         522.263999              19.565076  3.557560e+08   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "NaN           0.000000               0.000000  0.000000e+00   \n",
       "\n",
       "     occultationduration_min  \n",
       "NaN                     27.4  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  \n",
       "NaN                      0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IMPUTACIÓN DE VALORES AUSENTES\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "#df = df.drop(\"date\", axis=1)\n",
    "# Limpieza de datos: imputación valores ausentes (modelo).\n",
    "imp = SimpleImputer(missing_values=0, strategy='mean')\n",
    "imp.fit(df)\n",
    "\n",
    "aa = imp.transform(df)\n",
    "print(aa)\n",
    "display(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 2 while Y.shape[1] == 16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-a6526465ad59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoreatpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Dibujar gráfica de outliers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mgrafico_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutlier_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ok\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\VIU\\TFM\\repo\\Improve-MBSE-ML\\limpieza_funciones.py\u001b[0m in \u001b[0;36mgrafico_outliers\u001b[1;34m(df, outlier_method, outliers_begin, threshold, xmin, xmax)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrafico_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutlier_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutliers_begin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutlier_method\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_elliptic_envelope.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m    165\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mnegative_mahal_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnegative_mahal_dist\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_elliptic_envelope.py\u001b[0m in \u001b[0;36mscore_samples\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \"\"\"\n\u001b[0;32m    182\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmahalanobis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\covariance\\_empirical_covariance.py\u001b[0m in \u001b[0;36mmahalanobis\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;31m# compute mahalanobis distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         dist = pairwise_distances(X, self.location_[np.newaxis, :],\n\u001b[0m\u001b[0;32m    315\u001b[0m                                   metric='mahalanobis', VI=precision)\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1776\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m         X, Y = check_pairwise_arrays(X, Y, dtype=dtype,\n\u001b[0m\u001b[0;32m   1779\u001b[0m                                      force_all_finite=force_all_finite)\n\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    158\u001b[0m                              (X.shape[0], X.shape[1], Y.shape[0]))\n\u001b[0;32m    159\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[0m\u001b[0;32m    161\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m    162\u001b[0m                              X.shape[1], Y.shape[1]))\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 2 while Y.shape[1] == 16"
     ]
    }
   ],
   "source": [
    "#ENCUENTRA OUTLIERS PARA IDENTIFICAR ANOMALÍAS\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from limpieza_funciones import grafico_outliers\n",
    "\n",
    "# Carga de datos.\n",
    "# Limpieza de datos: detección de outliers.\n",
    "outlier_method = EllipticEnvelope().fit(df)\n",
    "scores_pred = outlier_method.decision_function(df)\n",
    "threshold = stats.scoreatpercentile(scores_pred, 25)\n",
    "# Dibujar gráfica de outliers.\n",
    "grafico_outliers(df, outlier_method, 150, threshold, -7, 7)\n",
    "\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-cf1ed409c19a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data == 0] = np.nan\n",
      "<ipython-input-44-cf1ed409c19a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data == 0] = np.nan\n",
      "<ipython-input-44-cf1ed409c19a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data == 0] = np.nan\n",
      "<ipython-input-44-cf1ed409c19a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data == 0] = np.nan\n",
      "<ipython-input-44-cf1ed409c19a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data == 0] = np.nan\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-585388b3ad14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#SE COMPRUEBAN LOS OUTLIERS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutliers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-cf1ed409c19a>\u001b[0m in \u001b[0;36mget_all_outliers\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0moutliers_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_outlier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0moutliers_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-cf1ed409c19a>\u001b[0m in \u001b[0;36mdetect_outlier\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m#mean_1 = np.mean(data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[0mtot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_divide_by_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[0misbad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-3920\\python-3.9.2.amd64\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\u001b[0m in \u001b[0;36m_divide_by_count\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[1;31m# This is questionable, but currently a numpy scalar can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "#SE COMPRUEBAN LOS OUTLIERS\n",
    "outliers = get_all_outliers(df)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
