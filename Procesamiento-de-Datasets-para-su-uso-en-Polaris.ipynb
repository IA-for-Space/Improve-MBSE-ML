{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install polaris-ml"
      ],
      "metadata": {
        "id": "rICw0MTsMtam",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4acf6428-30d0-4699-8dbe-e002169aa480"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polaris-ml\n",
            "  Downloading polaris_ml-0.13.5-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 81 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 92 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 102 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 122 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>0.23.0 in /usr/local/lib/python3.7/dist-packages (from polaris-ml) (1.0.1)\n",
            "Collecting vinvelivaanilai>=1.0.6\n",
            "  Downloading vinvelivaanilai-1.0.7-py2.py3-none-any.whl (30 kB)\n",
            "Collecting kaitaistruct\n",
            "  Downloading kaitaistruct-0.9.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from polaris-ml) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from polaris-ml) (1.1.5)\n",
            "Collecting satnogs-decoders\n",
            "  Downloading satnogs_decoders-1.29.1-py3-none-any.whl (307 kB)\n",
            "\u001b[K     |████████████████████████████████| 307 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting enlighten\n",
            "  Downloading enlighten-1.10.2-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting betsi-ml>=0.0.3\n",
            "  Downloading betsi_ml-0.0.4-py2.py3-none-any.whl (13 kB)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.22.0-py3-none-any.whl (15.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.5 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from polaris-ml) (4.62.3)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from polaris-ml) (0.90)\n",
            "Collecting fets\n",
            "  Downloading fets-0.5.3-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from polaris-ml) (7.1.2)\n",
            "Collecting mergedeep\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Collecting GPUtil==1.4.0\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Collecting glouton==0.11.1\n",
            "  Downloading glouton-0.11.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from glouton==0.11.1->polaris-ml) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.7/dist-packages (from betsi-ml>=0.0.3->polaris-ml) (2.7.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>0.23.0->polaris-ml) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>0.23.0->polaris-ml) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>0.23.0->polaris-ml) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.37.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.22.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.42.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (12.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.13.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->glouton==0.11.1->polaris-ml) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->glouton==0.11.1->polaris-ml) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->glouton==0.11.1->polaris-ml) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->glouton==0.11.1->polaris-ml) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.1.1)\n",
            "Collecting sphinx-autoapi>=1.4.0\n",
            "  Downloading sphinx_autoapi-1.8.4-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting sphinx-rtd-theme>=0.5.0\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 44.9 MB/s \n",
            "\u001b[?25hCollecting influxdb-client>=1.7.0\n",
            "  Downloading influxdb_client-1.24.0-py3-none-any.whl (524 kB)\n",
            "\u001b[K     |████████████████████████████████| 524 kB 44.6 MB/s \n",
            "\u001b[?25hCollecting sphinx>=3.1.1\n",
            "  Downloading Sphinx-4.3.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 44.5 MB/s \n",
            "\u001b[?25hCollecting poliastro>=0.15.0\n",
            "  Downloading poliastro-0.16.0-py3-none-any.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 53.1 MB/s \n",
            "\u001b[?25hCollecting orbit-predictor>=1.12.0\n",
            "  Downloading orbit_predictor-1.14.2-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 823 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astropy>=4.0.1.post1 in /usr/local/lib/python3.7/dist-packages (from vinvelivaanilai>=1.0.6->polaris-ml) (4.3.1)\n",
            "Requirement already satisfied: pyerfa>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from astropy>=4.0.1.post1->vinvelivaanilai>=1.0.6->polaris-ml) (2.0.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from influxdb-client>=1.7.0->vinvelivaanilai>=1.0.6->polaris-ml) (2.8.2)\n",
            "Collecting pytz>=2019.1\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting rx>=3.0.1\n",
            "  Downloading Rx-3.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 54.5 MB/s \n",
            "\u001b[?25hCollecting sgp4>=2.5\n",
            "  Downloading sgp4-2.20-cp37-cp37m-manylinux2010_x86_64.whl (258 kB)\n",
            "\u001b[K     |████████████████████████████████| 258 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting astroquery>=0.3.9\n",
            "  Downloading astroquery-0.4.5-py3-none-any.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly<6,>=4.0 in /usr/local/lib/python3.7/dist-packages (from poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (4.4.1)\n",
            "Requirement already satisfied: numba>=0.46 in /usr/local/lib/python3.7/dist-packages (from poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.51.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.1,>=2.0 in /usr/local/lib/python3.7/dist-packages (from poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (3.2.2)\n",
            "Collecting jplephem\n",
            "  Downloading jplephem-2.17.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting keyring>=4.0\n",
            "  Downloading keyring-23.5.0-py3-none-any.whl (33 kB)\n",
            "Collecting pyvo>=1.1\n",
            "  Downloading pyvo-1.2-py3-none-any.whl (832 kB)\n",
            "\u001b[K     |████████████████████████████████| 832 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: html5lib>=0.999 in /usr/local/lib/python3.7/dist-packages (from astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.0.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (4.6.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib>=0.999->astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.5.1)\n",
            "Collecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.1,>=2.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.1,>=2.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.1,>=2.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.11.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.46->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.34.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly<6,>=4.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.3.3)\n",
            "Collecting cryptography>=2.0\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (2.21)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.11.3)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.18,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (0.17.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.2.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.3.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.9.1)\n",
            "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.1.5)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (21.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (0.7.12)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 56.0 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.0.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from sphinx-autoapi>=1.4.0->vinvelivaanilai>=1.0.6->polaris-ml) (3.13)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting astroid>=2.7\n",
            "  Downloading astroid-2.9.3-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy>=1.4.0\n",
            "  Downloading lazy_object_proxy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting typed-ast<2.0,>=1.4.0\n",
            "  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 36.9 MB/s \n",
            "\u001b[?25hCollecting prefixed>=0.3.2\n",
            "  Downloading prefixed-0.3.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting blessed>=1.17.7\n",
            "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.7->enlighten->polaris-ml) (0.2.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->polaris-ml) (0.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->polaris-ml) (1.3.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->polaris-ml) (1.4.27)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.3 MB/s \n",
            "\u001b[?25hCollecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 51.2 MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 51.4 MB/s \n",
            "\u001b[?25hCollecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->polaris-ml) (0.4.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->polaris-ml) (1.1.4)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.7-py3-none-any.whl (17 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->polaris-ml) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->polaris-ml) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->polaris-ml) (1.1.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->polaris-ml) (0.12.0)\n",
            "Collecting enum34~=1.1.0\n",
            "  Downloading enum34-1.1.10-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: GPUtil, jplephem, kaitaistruct, alembic, databricks-cli\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=276040f7fad5b304598c64a72a529b6b609c24870f600c9196872442adc936f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for jplephem (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jplephem: filename=jplephem-2.17-py3-none-any.whl size=46326 sha256=db4f2d36bb1a85fb318af2a7d9b73158f437eb6b7c96057428344f13e51e9db7\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/fe/9c/2b3a1f7d639f9833f5cd79a2e62cb5d6f7901ee731e6cfd6e1\n",
            "  Building wheel for kaitaistruct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaitaistruct: filename=kaitaistruct-0.9-py2.py3-none-any.whl size=5512 sha256=93e7c901a6398ee23513c1cf0bf5f192aafeb787fa7e0224c53f99a8c08e295a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/59/67/5471a21f905f5cf5a9d47e3f43bfb87b13c69d63575fcade6b\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158172 sha256=9372ef4fd3b66649a88e6250beda022e711418f7c8c2518967636b212187d973\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=ea732957fd9cb25c8f6290c69a67dfd392f6ea6a550250eecf1aa724a1bd33a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/5c/ed/e1ce20a53095f63b27b4964abbad03e59cf3472822addf7d29\n",
            "Successfully built GPUtil jplephem kaitaistruct alembic databricks-cli\n",
            "Installing collected packages: jeepney, cryptography, SecretStorage, pytz, typed-ast, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, smmap, pyvo, lazy-object-proxy, keyring, websocket-client, unidecode, sphinx, sgp4, rx, PyYAML, python-editor, Mako, jplephem, gitdb, astroquery, astroid, sphinx-rtd-theme, sphinx-autoapi, querystring-parser, prometheus-flask-exporter, prefixed, poliastro, orbit-predictor, kaitaistruct, influxdb-client, gunicorn, gitpython, enum34, docker, databricks-cli, blessed, alembic, vinvelivaanilai, satnogs-decoders, mlflow, mergedeep, GPUtil, glouton, fets, enlighten, betsi-ml, polaris-ml\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 1.8.6\n",
            "    Uninstalling Sphinx-1.8.6:\n",
            "      Successfully uninstalled Sphinx-1.8.6\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GPUtil-1.4.0 Mako-1.1.6 PyYAML-6.0 SecretStorage-3.3.1 alembic-1.4.1 astroid-2.9.3 astroquery-0.4.5 betsi-ml-0.0.4 blessed-1.19.0 cryptography-36.0.1 databricks-cli-0.16.2 docker-5.0.3 enlighten-1.10.2 enum34-1.1.10 fets-0.5.3 gitdb-4.0.9 gitpython-3.1.26 glouton-0.11.1 gunicorn-20.1.0 influxdb-client-1.24.0 jeepney-0.7.1 jplephem-2.17 kaitaistruct-0.9 keyring-23.5.0 lazy-object-proxy-1.7.1 mergedeep-1.3.4 mlflow-1.22.0 orbit-predictor-1.14.2 polaris-ml-0.13.5 poliastro-0.16.0 prefixed-0.3.2 prometheus-flask-exporter-0.18.7 python-editor-1.0.4 pytz-2021.3 pyvo-1.2 querystring-parser-1.2.4 rx-3.2.0 satnogs-decoders-1.29.1 sgp4-2.20 smmap-5.0.0 sphinx-4.3.2 sphinx-autoapi-1.8.4 sphinx-rtd-theme-1.0.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 typed-ast-1.5.1 unidecode-1.3.2 vinvelivaanilai-1.0.7 websocket-client-1.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum",
                  "pytz",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlwcETrdgSBZ",
        "outputId": "80d937e4-3ea8-4554-9ccd-bb2dafc31ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "['./mars_express/context--2008-08-22_2010-07-10--ftl.csv', './mars_express/context--2008-08-22_2010-07-10--evtf.csv', './mars_express/context--2012-05-27_2014-04-14--evtf.csv', './mars_express/context--2008-08-22_2010-07-10--saaf.csv', './mars_express/context--2010-07-10_2012-05-27--saaf.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "os.listdir(\"./\")\n",
        "lista_archivos_lightsail = [x for x in os.listdir(\"./\") if x[-3:] == \"txt\"]\n",
        "lista_archivos_marsexpress = [\"./mars_express/\" + x for x in os.listdir(\"./mars_express/\") if x[-3:] == \"csv\"]\n",
        "print(lista_archivos_lightsail[:5])\n",
        "print(lista_archivos_marsexpress[:5])\n",
        "#os.getcwd()\n",
        "#os.path.getsize(\"2127458.txt\")\n",
        "#os.path.isfile(\"2127458.txt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DATASET PARA LECTURA HUMANA DEL LIGHTSAIL\n",
        "\n",
        "def read_human_from_txt_lightsail(lista_archivos):\n",
        "\n",
        "  etiquetas=[\"Observed_at\", \"Posted_at\"]\n",
        "\n",
        "  etiquetas2=[]\n",
        "\n",
        "  dataset={}\n",
        "\n",
        "  dataset[etiquetas[0]]=[]\n",
        "  dataset[etiquetas[1]]=[]\n",
        "\n",
        "  valores = []\n",
        "  valores2 = []\n",
        "\n",
        "  archivo1 = open(lista_archivos[0], \"r\")\n",
        "\n",
        "  for linea in archivo1:\n",
        "    if \"Observed at\" in linea:\n",
        "      valor = linea.split(\"at:\")[1].strip()\n",
        "      dataset[\"Observed_at\"].append(valor)\n",
        "    elif \"Posted at\" in linea:\n",
        "      valor = linea.split(\"at:\")[1].strip()\n",
        "      dataset[\"Posted_at\"].append(valor)\n",
        "    elif \":\" in linea and \"=\" in linea:\n",
        "      etiqueta = linea.split(\":\")[1].split(\"=\")[0].strip().replace(\" \", \"_\").replace(\"[\", \"_\").replace(\"]\", \"_\").replace(\"<\", \"_\")\n",
        "      valor = linea.split(\":\")[1].split(\"=\")[1].split(\"[\")[0].strip()\n",
        "      dataset[etiqueta]=[]\n",
        "      dataset[etiqueta].append(valor)\n",
        "\n",
        "  for nombre_archivo in lista_archivos[1:]:    \n",
        "    archivo = open(nombre_archivo, \"r\")\n",
        "    for linea in archivo: \n",
        "      if \"Observed at\" in linea:\n",
        "        valor = linea.split(\"at:\")[1].strip()\n",
        "        dataset[\"Observed_at\"].append(valor)\n",
        "      elif \"Posted at\" in linea:\n",
        "        valor = linea.split(\"at:\")[1].strip()\n",
        "        dataset[\"Posted_at\"].append(valor)\n",
        "      elif \":\" in linea and \"=\" in linea:\n",
        "        etiqueta = linea.split(\":\")[1].split(\"=\")[0].strip().replace(\" \", \"_\").replace(\"[\", \"_\").replace(\"]\", \"_\").replace(\"<\", \"_\")\n",
        "        valor = linea.split(\":\")[1].split(\"=\")[1].split(\"[\")[0].strip()\n",
        "        dataset[etiqueta].append(valor)\n",
        "\n",
        "  df = pd.DataFrame(dataset.values(), dataset.keys())\n",
        "  df = df.transpose()\n",
        "  return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mKOK2W_sacnM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LECTURA DE LOS DATASETS DE LIGHTSAIL Y MARS EXPRESS\n",
        "from datetime import datetime\n",
        "\n",
        "def transform_unix_to_utc(series):\n",
        "  if len(series) > 0:\n",
        "    new_series = [str(datetime.utcfromtimestamp(x/1000)) for x in series]\n",
        "    return new_series\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "def read_from_txt_lightsail():\n",
        "  etiquetas=[]\n",
        "  dataset={}\n",
        "  archivo1 = open(lista_archivos[0], \"r\")\n",
        "  kvp_form = False\n",
        "\n",
        "  for linea in archivo1:\n",
        "    if \"KVP form:\" in linea:\n",
        "      kvp_form = True\n",
        "    if kvp_form == True and \"=\" in linea:\n",
        "        etiqueta = linea.split(\"=\")[0].strip()\n",
        "        valor = float(linea.split(\"=\")[1].split(\",\")[0].strip())\n",
        "        dataset[etiqueta]=[]\n",
        "        dataset[etiqueta].append(valor)\n",
        "\n",
        "  for nombre_archivo in lista_archivos[1:]:    \n",
        "    archivo = open(nombre_archivo, \"r\")\n",
        "    kvp_form = False\n",
        "    for linea in archivo: \n",
        "      if \"KVP form:\" in linea:\n",
        "        kvp_form = True\n",
        "      if kvp_form == True and \"=\" in linea:\n",
        "        etiqueta = linea.split(\"=\")[0].strip()\n",
        "        valor = float(linea.split(\"=\")[1].split(\",\")[0].strip())\n",
        "        dataset[etiqueta].append(valor)\n",
        "\n",
        "  df = pd.DataFrame(dataset.values(), dataset.keys())\n",
        "  df = df.transpose()\n",
        "  return df\n",
        "\n",
        "\n",
        "def read_from_ut_ms(lista_archivos):\n",
        "  columnas = []\n",
        "  for archivo in lista_archivos:\n",
        "    df1 = pd.read_csv(archivo)\n",
        "    columnas += list(df1.columns)\n",
        "    columnas = list(set(columnas))\n",
        "  \n",
        "  df = pd.DataFrame(columns=columnas)\n",
        "  df = df.loc[:,~df.columns.duplicated()]\n",
        "  for archivo in lista_archivos:\n",
        "    df2 = pd.read_csv(archivo)\n",
        "    df2[\"date\"] = transform_unix_to_utc(df2[\"ut_ms\"])\n",
        "    df = df.append(df2)    \n",
        "  return df\n",
        "\n",
        "def read_from_utb_ms(lista_archivos):\n",
        "  columnas = []\n",
        "  for archivo in lista_archivos:\n",
        "    df1 = pd.read_csv(archivo)\n",
        "    columnas = list(df1.columns)\n",
        "    columnas.append(\"date\")\n",
        "  df = pd.DataFrame(columns=columnas)\n",
        "  for archivo in lista_archivos:\n",
        "    df2 = pd.read_csv(archivo)\n",
        "    df2[\"date\"] = transform_unix_to_utc(df2[\"utb_ms\"])\n",
        "    df = df.append(df2)\n",
        "  return df\n",
        "\n",
        "def read_from_csv_mars_express(lista_archivos):\n",
        "\n",
        "  lista_archivos_saaf = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"saaf\"]\n",
        "  lista_archivos_dmop = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"dmop\"]\n",
        "  lista_archivos_ftl = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"ftl\"]\n",
        "  lista_archivos_evtf = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"evtf\"]\n",
        "  lista_archivos_ltdata = [x for x in lista_archivos_marsexpress if x.split(\"--\")[-1].split(\".\")[0] == \"ltdata\"]\n",
        "\n",
        "  df_saaf = read_from_ut_ms(lista_archivos_saaf)\n",
        "  df_dmop = read_from_ut_ms(lista_archivos_dmop)\n",
        "  df_ftl = read_from_utb_ms(lista_archivos_ftl)\n",
        "  df_evtf = read_from_ut_ms(lista_archivos_evtf)\n",
        "  df_ltdata = read_from_ut_ms(lista_archivos_ltdata)\n",
        "\n",
        "  all_columns = list(df_saaf.columns) + list(df_dmop.columns) + list(df_ftl.columns) + list(df_evtf.columns) + list(df_ltdata.columns)\n",
        "  all_columns = list(set(all_columns))\n",
        "\n",
        "  df = pd.DataFrame(columns=all_columns)\n",
        "  df = df.append(df_saaf, ignore_index=True)\n",
        "  df = df.append(df_dmop, ignore_index=True)\n",
        "  df = df.append(df_ftl, ignore_index=True)\n",
        "  df = df.append(df_evtf, ignore_index=True)\n",
        "  df = df.append(df_ltdata, ignore_index=True).sort_values(\"date\")\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OSL_Yph0WzBZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#COMPROBAR RESULTADOS ANTES DE UTILIZAR POLARIS\n",
        "df = read_machine_from_csv(lista_archivos_marsexpress)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "sbj0GWnPysEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "outputId": "d85f37dd-bb2e-4ea3-86e1-7ac722e64309"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fa3e0168-7424-4f4f-9f13-c5299d0c98ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sy</th>\n",
              "      <th>description</th>\n",
              "      <th>solarconstantmars</th>\n",
              "      <th>sz</th>\n",
              "      <th>utb_ms</th>\n",
              "      <th>type</th>\n",
              "      <th>occultationduration_min</th>\n",
              "      <th>sx</th>\n",
              "      <th>date</th>\n",
              "      <th>sa</th>\n",
              "      <th>ute_ms</th>\n",
              "      <th>subsystem</th>\n",
              "      <th>sunmarsearthangle_deg</th>\n",
              "      <th>eclipseduration_min</th>\n",
              "      <th>earthmars_km</th>\n",
              "      <th>flagcomms</th>\n",
              "      <th>sunmars_km</th>\n",
              "      <th>ut_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3155780</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>522.264</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-08-22 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.5651</td>\n",
              "      <td>4.16667</td>\n",
              "      <td>3.55756e+08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.41939e+08</td>\n",
              "      <td>1219363200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2672561</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-08-22 00:00:11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AXXX301A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1219363211000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2894676</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1219363213000</td>\n",
              "      <td>EARTH</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-08-22 00:00:13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1219365494000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90.32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>104.55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.55</td>\n",
              "      <td>2008-08-22 00:00:13</td>\n",
              "      <td>0.32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1219363213000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>104.55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.56</td>\n",
              "      <td>2008-08-22 00:00:35</td>\n",
              "      <td>0.34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1219363235000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002420</th>\n",
              "      <td>NaN</td>\n",
              "      <td>MSL_/_RANGE_06000KM_START</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-04-13 23:56:47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1397433407000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2364778</th>\n",
              "      <td>88.59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2014-04-13 23:57:44</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1397433464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002421</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4000_KM_DESCEND</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-04-13 23:58:38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1397433518000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2364779</th>\n",
              "      <td>88.59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2014-04-13 23:58:44</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1397433524000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2364780</th>\n",
              "      <td>88.59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2014-04-13 23:59:44</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1397433584000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3156467 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa3e0168-7424-4f4f-9f13-c5299d0c98ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa3e0168-7424-4f4f-9f13-c5299d0c98ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa3e0168-7424-4f4f-9f13-c5299d0c98ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            sy                description  ...   sunmars_km          ut_ms\n",
              "3155780    NaN                        NaN  ...  2.41939e+08  1219363200000\n",
              "2672561    NaN                        NaN  ...          NaN  1219363211000\n",
              "2894676    NaN                        NaN  ...          NaN            NaN\n",
              "0        90.32                        NaN  ...          NaN  1219363213000\n",
              "1        90.34                        NaN  ...          NaN  1219363235000\n",
              "...        ...                        ...  ...          ...            ...\n",
              "3002420    NaN  MSL_/_RANGE_06000KM_START  ...          NaN  1397433407000\n",
              "2364778  88.59                        NaN  ...          NaN  1397433464000\n",
              "3002421    NaN            4000_KM_DESCEND  ...          NaN  1397433518000\n",
              "2364779  88.59                        NaN  ...          NaN  1397433524000\n",
              "2364780  88.59                        NaN  ...          NaN  1397433584000\n",
              "\n",
              "[3156467 rows x 18 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WmpHtEkGWJuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GUARDAR CSV DEL LIGHTSAIL2 PARA PROCESAMIENTO DE POLARIS\n",
        "df_csv = df.to_csv('lightsail_dataset.csv',sep=',', index=False)\n"
      ],
      "metadata": {
        "id": "wzPPwEj0jM29"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GUARDAR CSV DEL MARS EXPRESS PARA PROCESAMIENTO DE POLARIS\n",
        "df_csv = df.to_csv('marsexpress_dataset.csv',sep=',', index=False)"
      ],
      "metadata": {
        "id": "benZjPIheBK1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANALISYS.PY DE POLARIS, PARA PODER PERSONALIZARLO SEGÚN EL DATASET CONVENGA\n",
        "\n",
        "\"\"\"\n",
        "Module to launch different data analysis.\n",
        "\"\"\"\n",
        "import logging\n",
        "\n",
        "from fets.math import TSIntegrale\n",
        "from mlflow import set_experiment\n",
        "\n",
        "from polaris.data.graph import PolarisGraph\n",
        "from polaris.data.readers import read_polaris_data\n",
        "from polaris.dataset.metadata import PolarisMetadata\n",
        "from polaris.learn.feature.extraction import create_list_of_transformers, \\\n",
        "    extract_best_features\n",
        "from polaris.learn.predictor.cross_correlation import XCorr\n",
        "from polaris.learn.predictor.cross_correlation_configurator import \\\n",
        "    CrossCorrelationConfigurator\n",
        "\n",
        "LOGGER = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class NoFramesInInputFile(Exception):\n",
        "    \"\"\"Raised when frames dataframe is empty\"\"\"\n",
        "\n",
        "\n",
        "def feature_extraction(input_file, param_col):\n",
        "    \"\"\"\n",
        "    Start feature extraction using the given settings.\n",
        "\n",
        "        :param input_file: Path of a CSV file that will be\n",
        "            converted to a dataframe\n",
        "        :type input_file: str\n",
        "        :param param_col: Target column name\n",
        "        :type param_col: str\n",
        "    \"\"\"\n",
        "    # Create a small list of two transformers which will generate two\n",
        "    # different pipelines\n",
        "    transformers = create_list_of_transformers([\"5min\", \"15min\"], TSIntegrale)\n",
        "\n",
        "    # Extract the best features of the two pipelines\n",
        "    out = extract_best_features(input_file,\n",
        "                                transformers,\n",
        "                                target_column=param_col,\n",
        "                                time_unit=\"ms\")\n",
        "\n",
        "    # out[0] is the FeatureImportanceOptimization object\n",
        "    # from polaris.learn.feature.selection\n",
        "    # pylint: disable=E1101\n",
        "    print(out[0].best_features)\n",
        "\n",
        "\n",
        "# pylint: disable-msg=too-many-arguments\n",
        "def cross_correlate(input_file,\n",
        "                    output_graph_file=None,\n",
        "                    xcorr_configuration_file=None,\n",
        "                    graph_link_threshold=0.1,\n",
        "                    use_gridsearch=False,\n",
        "                    csv_sep=',',\n",
        "                    force_cpu=False):\n",
        "    \"\"\"\n",
        "    Catch linear and non-linear correlations between all columns of the\n",
        "    input data.\n",
        "\n",
        "        :param input_file: CSV or JSON file path that will be\n",
        "            converted to a dataframe\n",
        "        :type input_file: str\n",
        "        :param output_graph_file: Output file path for the generated graph.\n",
        "            It will overwrite if the file already exists. Defaults to None,\n",
        "            which is'/tmp/polaris_graph.json'\n",
        "        :type output_graph_file: str, optional\n",
        "        :param xcorr_configuration_file: XCorr configuration file path,\n",
        "            defaults to None. Refer to CrossCorrelationConfigurator for\n",
        "            the default parameters\n",
        "        :type xcorr_configuration_file: str, optional\n",
        "        :param graph_link_threshold: Minimum link value to be considered\n",
        "            as a link between two nodes\n",
        "        :type graph_link_threshold: float, optional\n",
        "        :param use_gridsearch: Use grid search for the cross correlation.\n",
        "            If this is set to False, then it will just use regression.\n",
        "            Defaults to False\n",
        "        :type use_gridsearch: bool, optional\n",
        "        :param csv_sep: The character that separates the columns inside of\n",
        "            the CSV file, defaults to ','\n",
        "        :type csv_sep: str, optional\n",
        "        :param force_cpu: Force CPU for cross corelation, defaults to False\n",
        "        :type force_cpu: bool, optional\n",
        "        :raises NoFramesInInputFile: If there are no frames in the converted\n",
        "            dataframe\n",
        "    \"\"\"\n",
        "    # Reading input file - index is considered on first column\n",
        "    metadata, dataframe = read_polaris_data(input_file, csv_sep)\n",
        "\n",
        "    if dataframe.empty:\n",
        "        LOGGER.error(\"Empty list of frames -- nothing to learn from!\")\n",
        "        raise NoFramesInInputFile\n",
        "\n",
        "    input_data = normalize_dataframe(dataframe)\n",
        "    source = metadata['satellite_name']\n",
        "\n",
        "    set_experiment(experiment_name=source)\n",
        "\n",
        "    xcorr_configurator = CrossCorrelationConfigurator(\n",
        "        xcorr_configuration_file=xcorr_configuration_file,\n",
        "        use_gridsearch=use_gridsearch,\n",
        "        force_cpu=force_cpu)\n",
        "\n",
        "    # Creating and fitting cross-correlator\n",
        "    xcorr = XCorr(metadata, xcorr_configurator.get_configuration())\n",
        "    xcorr.fit(input_data)\n",
        "\n",
        "    if output_graph_file is None:\n",
        "        output_graph_file = \"/tmp/polaris_graph.json\"\n",
        "\n",
        "    metadata = PolarisMetadata({\"satellite_name\": source})\n",
        "    graph = PolarisGraph(metadata=metadata)\n",
        "    graph.from_heatmap(xcorr.importances_map, graph_link_threshold)\n",
        "    with open(output_graph_file, 'w') as graph_file:\n",
        "        graph_file.write(graph.to_json())\n",
        "\n",
        "\n",
        "def normalize_dataframe(dataframe):\n",
        "    \"\"\"\n",
        "        Apply dataframe modification so it's compatible\n",
        "        with the learn module. The time column is first\n",
        "        set as the index of the dataframe. Then, we drop\n",
        "        the time column.\n",
        "\n",
        "        :param dataframe: The pandas dataframe to normalize\n",
        "        :type dataframe: pd.DataFrame\n",
        "        :return: Pandas dataframe normalized\n",
        "        :rtype: pd.DataFrame\n",
        "    \"\"\"\n",
        "    dataframe.index = dataframe.date\n",
        "    dataframe.drop(['date'], axis=1, inplace=True)\n",
        "\n",
        "    return dataframe\n"
      ],
      "metadata": {
        "id": "PoDmNLQib2tg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GENERA EL GRAFO DE LIGHTSAIL2\n",
        "cross_correlate(\"lightsail_dataset.csv\")\n"
      ],
      "metadata": {
        "id": "-SLFiMJXiTeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GENERA EL GRAFO DE MARS EXPRESS\n",
        "cross_correlate(\"marsexpress_dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Z0vAEqPbePhd",
        "outputId": "e727f3c9-9867-4397-e0fb-df8332c47a33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "2022/01/10 21:18:19 INFO mlflow.tracking.fluent: Experiment with name 'marsexpress_dataset' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "</style>\n",
              "<div class=\"enlighten\">\n",
              "  <div class=\"enlighten-bar\">\n",
              "    <pre>Columns 100%|████████████████████████████████████████████████████| 5/5 [01:01&lt;00:00, 0.08 columns/s]</pre>\n",
              "  </div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}