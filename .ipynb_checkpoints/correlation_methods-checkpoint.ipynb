{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rICw0MTsMtam",
    "outputId": "4acf6428-30d0-4699-8dbe-e002169aa480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polaris-ml\n",
      "  Using cached polaris_ml-0.13.5-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: fets in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (0.5.3)\n",
      "Requirement already satisfied: click in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (8.0.3)\n",
      "Collecting GPUtil==1.4.0\n",
      "  Using cached GPUtil-1.4.0-py3-none-any.whl\n",
      "Collecting kaitaistruct\n",
      "  Using cached kaitaistruct-0.9-py2.py3-none-any.whl\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: scikit-learn>0.23.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (1.0.2)\n",
      "Requirement already satisfied: enlighten in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (1.10.2)\n",
      "Requirement already satisfied: mlflow in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (1.23.0)\n",
      "Collecting vinvelivaanilai>=1.0.6\n",
      "  Using cached vinvelivaanilai-1.0.7-py2.py3-none-any.whl (30 kB)\n",
      "Collecting satnogs-decoders\n",
      "  Using cached satnogs_decoders-1.29.1-py3-none-any.whl (307 kB)\n",
      "Collecting betsi-ml>=0.0.3\n",
      "  Using cached betsi_ml-0.0.4-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (1.2.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (1.20.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from polaris-ml) (1.5.2)\n",
      "Collecting glouton==0.11.1\n",
      "  Using cached glouton-0.11.1-py2.py3-none-any.whl (39 kB)\n",
      "Collecting mergedeep\n",
      "  Using cached mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from glouton==0.11.1->polaris-ml) (2.27.1)\n",
      "Collecting tensorflow>=2.0\n",
      "  Using cached tensorflow-2.7.0-cp39-cp39-win_amd64.whl (430.8 MB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>0.23.0->polaris-ml) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>0.23.0->polaris-ml) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>0.23.0->polaris-ml) (3.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.7.0)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\manue\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.15.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-12.0.0-2-py2.py3-none-win_amd64.whl (13.0 MB)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.13.3)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.6.0-cp39-cp39-win_amd64.whl (2.8 MB)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.23.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.7.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.43.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (4.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.19.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (49.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.0.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (4.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->glouton==0.11.1->polaris-ml) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->glouton==0.11.1->polaris-ml) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->glouton==0.11.1->polaris-ml) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->glouton==0.11.1->polaris-ml) (1.26.8)\n",
      "Requirement already satisfied: oauthlib<3.0.0,>=2.1.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0->betsi-ml>=0.0.3->polaris-ml) (2.1.0)\n",
      "Collecting sphinx-autoapi>=1.4.0\n",
      "  Using cached sphinx_autoapi-1.8.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting sphinx-rtd-theme>=0.5.0\n",
      "  Using cached sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Requirement already satisfied: astropy>=4.0.1.post1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from vinvelivaanilai>=1.0.6->polaris-ml) (4.3.1)\n",
      "Requirement already satisfied: sphinx>=3.1.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from vinvelivaanilai>=1.0.6->polaris-ml) (4.4.0)\n",
      "Collecting orbit-predictor>=1.12.0\n",
      "  Using cached orbit_predictor-1.14.2-py3-none-any.whl (42 kB)\n",
      "Collecting influxdb-client>=1.7.0\n",
      "  Using cached influxdb_client-1.24.0-py3-none-any.whl (524 kB)\n",
      "Collecting poliastro>=0.15.0\n",
      "  Using cached poliastro-0.16.0-py3-none-any.whl (143 kB)\n",
      "Requirement already satisfied: pyerfa>=1.7.3 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astropy>=4.0.1.post1->vinvelivaanilai>=1.0.6->polaris-ml) (2.0.0.1)\n",
      "Requirement already satisfied: pytz>=2019.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from influxdb-client>=1.7.0->vinvelivaanilai>=1.0.6->polaris-ml) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\manue\\appdata\\roaming\\python\\python39\\site-packages (from influxdb-client>=1.7.0->vinvelivaanilai>=1.0.6->polaris-ml) (2.8.1)\n",
      "Requirement already satisfied: rx>=3.0.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from influxdb-client>=1.7.0->vinvelivaanilai>=1.0.6->polaris-ml) (3.2.0)\n",
      "Requirement already satisfied: sgp4>=2.5 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from orbit-predictor>=1.12.0->vinvelivaanilai>=1.0.6->polaris-ml) (2.20)\n",
      "Collecting astroquery>=0.3.9\n",
      "  Using cached astroquery-0.4.5-py3-none-any.whl (4.5 MB)\n",
      "Collecting plotly<6,>=4.0\n",
      "  Using cached plotly-5.5.0-py2.py3-none-any.whl (26.5 MB)\n",
      "Requirement already satisfied: matplotlib!=3.0.1,>=2.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (3.4.2)\n",
      "Collecting jplephem\n",
      "  Using cached jplephem-2.17-py3-none-any.whl\n",
      "Collecting numba>=0.53.0\n",
      "  Using cached numba-0.55.0-cp39-cp39-win_amd64.whl (2.4 MB)\n",
      "Requirement already satisfied: pyvo>=1.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.2.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.3.2 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (4.10.0)\n",
      "Requirement already satisfied: html5lib>=0.999 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.1)\n",
      "Requirement already satisfied: keyring>=4.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (23.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4>=4.3.2->astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (2.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from html5lib>=0.999->astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.5.1)\n",
      "Requirement already satisfied: pywin32-ctypes!=0.1.0,!=0.1.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keyring>=4.0->astroquery>=0.3.9->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.0.1,>=2.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.0.1,>=2.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.0.1,>=2.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.0.1,>=2.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (2.4.7)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba>=0.53.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (0.38.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly<6,>=4.0->poliastro>=0.15.0->vinvelivaanilai>=1.0.6->polaris-ml) (8.0.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.9.1)\n",
      "Requirement already satisfied: imagesize in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.3.0)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\manue\\appdata\\roaming\\python\\python39\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.8.1)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\manue\\appdata\\roaming\\python\\python39\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (0.4.4)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.0.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (21.3)\n",
      "Requirement already satisfied: docutils<0.18,>=0.14 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (0.17.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (3.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (1.0.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (0.7.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Jinja2>=2.3->sphinx>=3.1.1->vinvelivaanilai>=1.0.6->polaris-ml) (2.0.1)\n",
      "Requirement already satisfied: unidecode in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx-autoapi>=1.4.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.3.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sphinx-autoapi>=1.4.0->vinvelivaanilai>=1.0.6->polaris-ml) (6.0)\n",
      "Collecting astroid>=2.7\n",
      "  Using cached astroid-2.9.3-py3-none-any.whl (254 kB)\n",
      "Requirement already satisfied: lazy-object-proxy>=1.4.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astroid>=2.7->sphinx-autoapi>=1.4.0->vinvelivaanilai>=1.0.6->polaris-ml) (1.7.1)\n",
      "Requirement already satisfied: prefixed>=0.3.2 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from enlighten->polaris-ml) (0.3.2)\n",
      "Requirement already satisfied: blessed>=1.17.7 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from enlighten->polaris-ml) (1.19.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in c:\\users\\manue\\appdata\\roaming\\python\\python39\\site-packages (from blessed>=1.17.7->enlighten->polaris-ml) (0.2.5)\n",
      "Requirement already satisfied: jinxed>=1.1.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from blessed>=1.17.7->enlighten->polaris-ml) (1.1.0)\n",
      "Requirement already satisfied: ansicon in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinxed>=1.1.0->blessed>=1.17.7->enlighten->polaris-ml) (1.89.0)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (0.16.2)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (3.1.26)\n",
      "Requirement already satisfied: querystring-parser in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (1.2.4)\n",
      "Requirement already satisfied: prometheus-flask-exporter in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (0.18.7)\n",
      "Requirement already satisfied: waitress in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (2.0.0)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (1.4.29)\n",
      "Requirement already satisfied: Flask in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (2.0.2)\n",
      "Requirement already satisfied: docker>=4.0.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (5.0.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (0.3)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (0.4.2)\n",
      "Requirement already satisfied: alembic in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (1.7.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mlflow->polaris-ml) (2.0.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from databricks-cli>=0.8.7->mlflow->polaris-ml) (0.8.9)\n",
      "Requirement already satisfied: pywin32==227 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from docker>=4.0.0->mlflow->polaris-ml) (227)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from docker>=4.0.0->mlflow->polaris-ml) (1.2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gitpython>=2.1.0->mlflow->polaris-ml) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->polaris-ml) (5.0.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from alembic->mlflow->polaris-ml) (1.1.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sqlalchemy->mlflow->polaris-ml) (1.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Flask->mlflow->polaris-ml) (2.0.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\manue\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prometheus-flask-exporter->mlflow->polaris-ml) (0.12.0)\n",
      "Collecting enum34~=1.1.0\n",
      "  Using cached enum34-1.1.10-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: plotly, opt-einsum, numba, libclang, keras-preprocessing, keras, jplephem, h5py, google-pasta, gast, flatbuffers, astunparse, astroquery, astroid, tensorflow, sphinx-rtd-theme, sphinx-autoapi, poliastro, orbit-predictor, kaitaistruct, influxdb-client, enum34, vinvelivaanilai, tqdm, satnogs-decoders, mergedeep, GPUtil, glouton, betsi-ml, polaris-ml\n",
      "Successfully installed GPUtil-1.4.0 astroid-2.9.3 astroquery-0.4.5 astunparse-1.6.3 betsi-ml-0.0.4 enum34-1.1.10 flatbuffers-2.0 gast-0.4.0 glouton-0.11.1 google-pasta-0.2.0 h5py-3.6.0 influxdb-client-1.24.0 jplephem-2.17 kaitaistruct-0.9 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 mergedeep-1.3.4 numba-0.55.0 opt-einsum-3.3.0 orbit-predictor-1.14.2 plotly-5.5.0 polaris-ml-0.13.5 poliastro-0.16.0 satnogs-decoders-1.29.1 sphinx-autoapi-1.8.4 sphinx-rtd-theme-1.0.0 tensorflow-2.7.0 tqdm-4.62.3 vinvelivaanilai-1.0.7\n"
     ]
    }
   ],
   "source": [
    "#!pip install polaris-ml\r\n",
    "#!pip install fets\r\n",
    "#!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlwcETrdgSBZ",
    "outputId": "80d937e4-3ea8-4554-9ccd-bb2dafc31ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\r\n",
    "Cross Correlation module\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "import logging\r\n",
    "import warnings\r\n",
    "\r\n",
    "import enlighten\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from polaris.feature.cleaner import Cleaner\r\n",
    "# Used for tracking ML process results\r\n",
    "from mlflow import log_metric, log_param, log_params, start_run\r\n",
    "# Used for the pipeline interface of scikit learn\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\r\n",
    "\r\n",
    "# eXtreme Gradient Boost algorithm\r\n",
    "from xgboost import XGBRegressor\r\n",
    "\r\n",
    "#RandomForest\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "#Extratrees regressor\r\n",
    "from sklearn.ensemble import ExtraTreesRegressor\r\n",
    "\r\n",
    "#AdaBoostRegressor\r\n",
    "from sklearn.ensemble import AdaBoostRegressor\r\n",
    "\r\n",
    "#GradientBoostingRegressor\r\n",
    "from sklearn.ensemble import GradientBoostingRegressor\r\n",
    "\r\n",
    "#HistGradientBoostingRegressor\r\n",
    "#from sklearn.ensemble import HistGradientBoostingRegressor\r\n",
    "\r\n",
    "#VotingRegressor\r\n",
    "from sklearn.ensemble import VotingRegressor\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "\r\n",
    "LOGGER = logging.getLogger(__name__)\r\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\r\n",
    "# Remove this line when feature engineering is in place\r\n",
    "np.seterr(divide='ignore', invalid='ignore')\r\n",
    "\r\n",
    "\r\n",
    "class XCorr(BaseEstimator, TransformerMixin):\r\n",
    "    \"\"\" Cross Correlation predictor class\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, dataset_metadata, cross_correlation_params, regressor):\r\n",
    "        \"\"\" Initialize an XCorr object\r\n",
    "\r\n",
    "            :param dataset_metadata: The metadata of the dataset\r\n",
    "            :type dataset_metadata: PolarisMetadata\r\n",
    "            :param cross_correlation_params: XCorr parameters\r\n",
    "            :type cross_correlation_params: CrossCorrelationParameters\r\n",
    "        \"\"\"\r\n",
    "        self._regressor = regressor\r\n",
    "        self.models = None\r\n",
    "        self._importances_map = None\r\n",
    "        self._feature_cleaner = Cleaner(\r\n",
    "            dataset_metadata, cross_correlation_params.dataset_cleaning_params)\r\n",
    "        self.xcorr_params = {\r\n",
    "            \"random_state\": cross_correlation_params.random_state,\r\n",
    "            \"test_size\": cross_correlation_params.test_size,\r\n",
    "            \"gridsearch_scoring\": cross_correlation_params.gridsearch_scoring,\r\n",
    "            \"gridsearch_n_splits\":\r\n",
    "            cross_correlation_params.gridsearch_n_splits,\r\n",
    "        }\r\n",
    "        # If we're importing from CSV, the dataset_metadata may not\r\n",
    "        # have the feature_columns key.\r\n",
    "        try:\r\n",
    "            self.xcorr_params['feature_columns'] = dataset_metadata[\r\n",
    "                'analysis']['feature_columns']\r\n",
    "        except KeyError:\r\n",
    "            LOGGER.info(\r\n",
    "                \"No feature_columns entry in metatdata, setting to empty array\"\r\n",
    "            )\r\n",
    "            self.xcorr_params['feature_columns'] = []\r\n",
    "\r\n",
    "        if cross_correlation_params.use_gridsearch:\r\n",
    "            self.method = self.gridsearch\r\n",
    "            self.mlf_logging = self.gridsearch_mlf_logging\r\n",
    "        else:\r\n",
    "            self.method = self.regression\r\n",
    "            self.mlf_logging = self.regression_mlf_logging\r\n",
    "\r\n",
    "        self.model_params = {\r\n",
    "            \"current\": cross_correlation_params.model_params,\r\n",
    "            \"cpu\": cross_correlation_params.model_cpu_params\r\n",
    "        }\r\n",
    "        \r\n",
    "    @property\r\n",
    "    def regressor(self):\r\n",
    "        return self._regressor\r\n",
    "    \r\n",
    "    @regressor.setter\r\n",
    "    def regressor(self, regressor):\r\n",
    "        self._regressor = regressor\r\n",
    "\r\n",
    "    @property\r\n",
    "    def importances_map(self):\r\n",
    "        \"\"\"\r\n",
    "        Return the importances_map value as Pandas Dataframe.\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        return self._importances_map\r\n",
    "\r\n",
    "    @importances_map.setter\r\n",
    "    def importances_map(self, importances_map):\r\n",
    "        self._importances_map = importances_map\r\n",
    "\r\n",
    "    def fit(self, X):\r\n",
    "        \"\"\" Train on a dataframe\r\n",
    "\r\n",
    "            The input dataframe will be split column by column\r\n",
    "            considering each one as a prediction target.\r\n",
    "\r\n",
    "            :param X: Input dataframe\r\n",
    "            :type X: pd.DataFrame\r\n",
    "            :raises Exception: If encountered any unhandled error\r\n",
    "                during model fitting\r\n",
    "        \"\"\"\r\n",
    "        if not isinstance(X, pd.DataFrame):\r\n",
    "            raise TypeError(\"Input data should be a DataFrame\")\r\n",
    "\r\n",
    "        if self.models is None:\r\n",
    "            self.models = []\r\n",
    "\r\n",
    "        manager = enlighten.get_manager()\r\n",
    "\r\n",
    "        LOGGER.info(\"Clearing Data. Removing unnecessary columns\")\r\n",
    "        X = self._feature_cleaner.drop_constant_values(X)\r\n",
    "        X = self._feature_cleaner.drop_non_numeric_values(X)\r\n",
    "        X = self._feature_cleaner.handle_missing_values(X)\r\n",
    "\r\n",
    "        self.reset_importance_map(X.columns)\r\n",
    "\r\n",
    "        parameters = self.__build_parameters(X)\r\n",
    "\r\n",
    "        pbar = manager.counter(total=len(parameters),\r\n",
    "                               desc=\"Columns\",\r\n",
    "                               unit=\"columns\")\r\n",
    "\r\n",
    "        with start_run(run_name='cross_correlate', nested=True):\r\n",
    "            self.mlf_logging()\r\n",
    "            for column in parameters:\r\n",
    "                LOGGER.info(column)\r\n",
    "                try:\r\n",
    "                    self.models.append(\r\n",
    "                        self.method(X.drop([column], axis=1), X[column],\r\n",
    "                                    self.model_params['current']))\r\n",
    "                except Exception as err:  # pylint: disable-msg=broad-except\r\n",
    "                    if self.model_params['current'].get(\r\n",
    "                            \"predictor\") == \"gpu_predictor\":\r\n",
    "                        LOGGER.info(\" \".join([\r\n",
    "                            \"Encountered error using GPU.\",\r\n",
    "                            \"Trying with CPU parameters now!\"\r\n",
    "                        ]))\r\n",
    "                        self.model_params['current'] = self.model_params['cpu']\r\n",
    "                    else:\r\n",
    "                        raise err\r\n",
    "                pbar.update()\r\n",
    "\r\n",
    "    def transform(self):\r\n",
    "        \"\"\" Unused method in this predictor \"\"\"\r\n",
    "        return self\r\n",
    "    \r\n",
    "        \r\n",
    "    def regression(self, df_in, target_series, model_params):\r\n",
    "        \"\"\" Fit a model to predict target_series with df_in features/columns\r\n",
    "            and retain the features importances in the dependency matrix.\r\n",
    "\r\n",
    "            :param df_in: Input dataframe representing the context, predictors\r\n",
    "            :type df_in: pd.DataFrame\r\n",
    "            :param target_series: pandas series of the target variable. Share\r\n",
    "                the same indexes as the df_in dataframe\r\n",
    "            :type target_series: pd.Series\r\n",
    "            :param model_params: Parameters for the XGB model\r\n",
    "            :type model_params: dict\r\n",
    "            :return: A fitted XGBRegressor\r\n",
    "            :rtype: XGBRegressor\r\n",
    "        \"\"\"\r\n",
    "        # Split df_in and target to train and test dataset\r\n",
    "        df_in_train, df_in_test, target_train, target_test = train_test_split(\r\n",
    "            df_in,\r\n",
    "            target_series,\r\n",
    "            test_size=0.2,\r\n",
    "            random_state=self.xcorr_params['random_state'])\r\n",
    "\r\n",
    "\r\n",
    "        regressors_dict = {\"XGB\": XGBRegressor(**model_params),\r\n",
    "                           \"RandomForest\": RandomForestRegressor(),\r\n",
    "                           \"AdaBoost\": AdaBoostRegressor(),\r\n",
    "                           \"ExtraTrees\": ExtraTreesRegressor(),\r\n",
    "                           \"GradientBoosting\": GradientBoostingRegressor(),\r\n",
    "                           \"Voting\": \"VotingRegressor()\"}\r\n",
    "\r\n",
    "        \"\"\" if self._regressor == \"XGboosting\":\r\n",
    "            # Create and train a XGBoost regressor\r\n",
    "            regr_m = XGBRegressor(**model_params)\r\n",
    "            \r\n",
    "        elif self._regressor == \"RandomForest\":\r\n",
    "            # Create and train a Sci-kit regressor\r\n",
    "            regr_m = RandomForestRegressor()\r\n",
    "        \r\n",
    "        elif self._regressor == \"AdaBoost\":\r\n",
    "            # Create and train a Sci-kit regressor\r\n",
    "            regr_m = AdaBoostRegressor()\r\n",
    "        \r\n",
    "        elif self._regressor == \"ExtraTrees\":\r\n",
    "             # Create and train a Sci-kit regressor\r\n",
    "            regr_m = ExtraTreesRegressor()\r\n",
    "        \r\n",
    "        elif self._regressor == \"GradientBoosting\":\r\n",
    "            # Create and train a Sci-kit regressor\r\n",
    "            regr_m = GradientBoostingRegressor()\r\n",
    "        \r\n",
    "        elif self._regressor == \"HistGradientBoosting\":\r\n",
    "            # Create and train a Sci-kit regressor\r\n",
    "            #regr_m = HistGradientBoostingRegressor()\r\n",
    "            pass\r\n",
    "            \r\n",
    "        elif self._regressor == \"Voting\":\r\n",
    "            # Create and train a Sci-kit regressor\r\n",
    "            regr_m = VotingRegressor()\r\n",
    "        \r\n",
    "        \"\"\"\r\n",
    "        regr_m = regressors_dict[self._regressor]\r\n",
    "        regr_m.fit(df_in_train, target_train)\r\n",
    "\r\n",
    "        # Make predictions\r\n",
    "        target_series_predict = regr_m.predict(df_in_test)\r\n",
    "\r\n",
    "        try:\r\n",
    "            rmse = np.sqrt(\r\n",
    "                mean_squared_error(target_test, target_series_predict))\r\n",
    "            log_metric(target_series.name, rmse)\r\n",
    "            LOGGER.info('Making predictions for : %s', target_series.name)\r\n",
    "            LOGGER.info('Root Mean Square Error : %s', str(rmse))\r\n",
    "        except Exception:  # pylint: disable-msg=broad-except\r\n",
    "            # Because of large (close to infinite values) or nans\r\n",
    "            LOGGER.error('Cannot find RMS Error for %s', target_series.name)\r\n",
    "            LOGGER.debug('Expected %s, Predicted %s', str(target_test),\r\n",
    "                         str(target_series_predict))\r\n",
    "\r\n",
    "        # indices = np.argsort(regr_m.feature_importances_)[::-1]\r\n",
    "        # After the model is trained\r\n",
    "        new_row = {}\r\n",
    "        for column, feat_imp in zip(df_in.columns,\r\n",
    "                                    regr_m.feature_importances_):\r\n",
    "            new_row[column] = [feat_imp]\r\n",
    "\r\n",
    "        # Current target is not in df_in, so manually adding it\r\n",
    "        new_row[target_series.name] = [0.0]\r\n",
    "\r\n",
    "        # Sorting new_row to avoid concatenation warnings\r\n",
    "        new_row = dict(sorted(new_row.items()))\r\n",
    "\r\n",
    "        # Concatenating new information about feature importances\r\n",
    "        if self._importances_map is not None:\r\n",
    "            self._importances_map = pd.concat([\r\n",
    "                self._importances_map,\r\n",
    "                pd.DataFrame(index=[target_series.name], data=new_row)\r\n",
    "            ])\r\n",
    "        return regr_m\r\n",
    "\r\n",
    "    def gridsearch(self, df_in, target_series, params):\r\n",
    "        \"\"\" Apply grid search to fine-tune XGBoost hyperparameters\r\n",
    "            and then call the regression method with the best grid\r\n",
    "            search parameters.\r\n",
    "\r\n",
    "            :param df_in: Input dataframe representing the context, predictors\r\n",
    "            :type df_in: pd.DataFrame\r\n",
    "            :param target_series: Pandas series of the target variable. Share\r\n",
    "                the same indexes as the df_in dataframe\r\n",
    "            :type target_series: pd.Series\r\n",
    "            :param params: The hyperparameters to use on the gridsearch\r\n",
    "                method\r\n",
    "            :type params: dict\r\n",
    "            :raises TypeError: If df_in is not Pandas DataFrame\r\n",
    "            :return: A fitted XGBRegressor\r\n",
    "            :rtype: XGBRegressor\r\n",
    "        \"\"\"\r\n",
    "        if not isinstance(df_in, pd.DataFrame):\r\n",
    "            LOGGER.error(\"Expected %s got %s for df_in in gridsearch\",\r\n",
    "                         pd.DataFrame, type(df_in))\r\n",
    "            raise TypeError\r\n",
    "\r\n",
    "        random_state = self.xcorr_params['random_state']\r\n",
    "        kfolds = KFold(n_splits=self.xcorr_params['gridsearch_n_splits'],\r\n",
    "                       shuffle=True,\r\n",
    "                       random_state=random_state)\r\n",
    "        regr_m = XGBRegressor(random_state=random_state,\r\n",
    "                              predictor=\"cpu_predictor\",\r\n",
    "                              tree_method=\"auto\",\r\n",
    "                              n_jobs=-1)\r\n",
    "\r\n",
    "        gs_regr = GridSearchCV(regr_m,\r\n",
    "                               param_grid=params,\r\n",
    "                               cv=kfolds,\r\n",
    "                               scoring=self.xcorr_params['gridsearch_scoring'],\r\n",
    "                               n_jobs=-1,\r\n",
    "                               verbose=1)\r\n",
    "        gs_regr.fit(df_in, target_series)\r\n",
    "\r\n",
    "        log_param(target_series.name + ' best estimator', gs_regr.best_params_)\r\n",
    "        LOGGER.info(\"%s best estimator : %s\", target_series.name,\r\n",
    "                    str(gs_regr.best_estimator_))\r\n",
    "        return self.regression(df_in, target_series, gs_regr.best_params_)\r\n",
    "\r\n",
    "    def reset_importance_map(self, columns):\r\n",
    "        \"\"\"\r\n",
    "        Creating an empty importance map\r\n",
    "\r\n",
    "        :param columns: List of column names for the importance map\r\n",
    "        :rtype columns: pd.Index or array-like\r\n",
    "        \"\"\"\r\n",
    "        if self._importances_map is None:\r\n",
    "            self._importances_map = pd.DataFrame(data={}, columns=columns)\r\n",
    "\r\n",
    "    def common_mlf_logging(self):\r\n",
    "        \"\"\" Log the parameters used for gridsearch and regression\r\n",
    "            in mlflow\r\n",
    "        \"\"\"\r\n",
    "        log_param('Test size', self.xcorr_params['test_size'])\r\n",
    "        log_param('Model', 'XGBRegressor')\r\n",
    "\r\n",
    "    def gridsearch_mlf_logging(self):\r\n",
    "        \"\"\" Log the parameters used for gridsearch\r\n",
    "            in mlflow\r\n",
    "        \"\"\"\r\n",
    "        log_param('Gridsearch scoring',\r\n",
    "                  self.xcorr_params['gridsearch_scoring'])\r\n",
    "        log_param('Gridsearch parameters', self.model_params)\r\n",
    "        self.common_mlf_logging()\r\n",
    "\r\n",
    "    def regression_mlf_logging(self):\r\n",
    "        \"\"\" Log the parameters used for regression\r\n",
    "            in mlflow.\r\n",
    "        \"\"\"\r\n",
    "        self.common_mlf_logging()\r\n",
    "        log_params(self.model_params)\r\n",
    "\r\n",
    "    def __build_parameters(self, X):\r\n",
    "        \"\"\" Remove features only from\r\n",
    "            being predicted.\r\n",
    "\r\n",
    "            :param X: The dataset\r\n",
    "            :type X: pd.DataFrame\r\n",
    "            :return: List of remaining features that are not removed\r\n",
    "            :rtype: list\r\n",
    "        \"\"\"\r\n",
    "        if self.xcorr_params['feature_columns'] is None:\r\n",
    "            return list(X.columns)\r\n",
    "\r\n",
    "        LOGGER.info('Removing features from the parameters : %s',\r\n",
    "                    self.xcorr_params['feature_columns'])\r\n",
    "        feature_to_remove = set(self.xcorr_params['feature_columns'])\r\n",
    "\r\n",
    "        return [x for x in list(X.columns) if x not in feature_to_remove]\r\n",
    "    \r\n",
    "    \r\n",
    "    \r\n",
    "print(\"Ok\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\r\n",
    "Module to launch different data analysis.\r\n",
    "\"\"\"\r\n",
    "import logging\r\n",
    "\r\n",
    "from fets.math import TSIntegrale\r\n",
    "from mlflow import set_experiment\r\n",
    "import polaris\r\n",
    "from polaris.data.graph import PolarisGraph\r\n",
    "from polaris.data.readers import read_polaris_data\r\n",
    "from polaris.dataset.metadata import PolarisMetadata\r\n",
    "from polaris.learn.feature.extraction import create_list_of_transformers, \\\r\n",
    "    extract_best_features\r\n",
    "from polaris.learn.predictor.cross_correlation_configurator import \\\r\n",
    "    CrossCorrelationConfigurator\r\n",
    "\r\n",
    "LOGGER = logging.getLogger(__name__)\r\n",
    "\r\n",
    "\r\n",
    "class NoFramesInInputFile(Exception):\r\n",
    "    \"\"\"Raised when frames dataframe is empty\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "def feature_extraction(input_file, param_col):\r\n",
    "    \"\"\"\r\n",
    "    Start feature extraction using the given settings.\r\n",
    "\r\n",
    "        :param input_file: Path of a CSV file that will be\r\n",
    "            converted to a dataframe\r\n",
    "        :type input_file: str\r\n",
    "        :param param_col: Target column name\r\n",
    "        :type param_col: str\r\n",
    "    \"\"\"\r\n",
    "    # Create a small list of two transformers which will generate two\r\n",
    "    # different pipelines\r\n",
    "    transformers = create_list_of_transformers([\"5min\", \"15min\"], TSIntegrale)\r\n",
    "\r\n",
    "    # Extract the best features of the two pipelines\r\n",
    "    out = extract_best_features(input_file,\r\n",
    "                                transformers,\r\n",
    "                                target_column=param_col,\r\n",
    "                                time_unit=\"ms\")\r\n",
    "\r\n",
    "    # out[0] is the FeatureImportanceOptimization object\r\n",
    "    # from polaris.learn.feature.selection\r\n",
    "    # pylint: disable=E1101\r\n",
    "    print(out[0].best_features)\r\n",
    "\r\n",
    "\r\n",
    "# pylint: disable-msg=too-many-arguments\r\n",
    "def cross_correlate(input_file,\r\n",
    "                    regressor=\"XGB\",\r\n",
    "                    output_graph_file=None,\r\n",
    "                    xcorr_configuration_file=None,\r\n",
    "                    graph_link_threshold=0.1,\r\n",
    "                    use_gridsearch=False,\r\n",
    "                    csv_sep=',',\r\n",
    "                    force_cpu=False):\r\n",
    "    \"\"\"\r\n",
    "    Catch linear and non-linear correlations between all columns of the\r\n",
    "    input data.\r\n",
    "\r\n",
    "        :param input_file: CSV or JSON file path that will be\r\n",
    "            converted to a dataframe\r\n",
    "        :type input_file: str\r\n",
    "        :param output_graph_file: Output file path for the generated graph.\r\n",
    "            It will overwrite if the file already exists. Defaults to None,\r\n",
    "            which is'/tmp/polaris_graph.json'\r\n",
    "        :type output_graph_file: str, optional\r\n",
    "        :param xcorr_configuration_file: XCorr configuration file path,\r\n",
    "            defaults to None. Refer to CrossCorrelationConfigurator for\r\n",
    "            the default parameters\r\n",
    "        :type xcorr_configuration_file: str, optional\r\n",
    "        :param graph_link_threshold: Minimum link value to be considered\r\n",
    "            as a link between two nodes\r\n",
    "        :type graph_link_threshold: float, optional\r\n",
    "        :param use_gridsearch: Use grid search for the cross correlation.\r\n",
    "            If this is set to False, then it will just use regression.\r\n",
    "            Defaults to False\r\n",
    "        :type use_gridsearch: bool, optional\r\n",
    "        :param csv_sep: The character that separates the columns inside of\r\n",
    "            the CSV file, defaults to ','\r\n",
    "        :type csv_sep: str, optional\r\n",
    "        :param force_cpu: Force CPU for cross corelation, defaults to False\r\n",
    "        :type force_cpu: bool, optional\r\n",
    "        :raises NoFramesInInputFile: If there are no frames in the converted\r\n",
    "            dataframe\r\n",
    "    \"\"\"\r\n",
    "    # Reading input file - index is considered on first column\r\n",
    "    metadata, dataframe = read_polaris_data(input_file, csv_sep)\r\n",
    "\r\n",
    "    if dataframe.empty:\r\n",
    "        LOGGER.error(\"Empty list of frames -- nothing to learn from!\")\r\n",
    "        raise NoFramesInInputFile\r\n",
    "\r\n",
    "    input_data = normalize_dataframe(dataframe)\r\n",
    "    source = metadata['satellite_name']\r\n",
    "\r\n",
    "    set_experiment(experiment_name=source)\r\n",
    "\r\n",
    "    xcorr_configurator = CrossCorrelationConfigurator(\r\n",
    "        xcorr_configuration_file=xcorr_configuration_file,\r\n",
    "        use_gridsearch=use_gridsearch,\r\n",
    "        force_cpu=force_cpu)\r\n",
    "\r\n",
    "    # Creating and fitting cross-correlator\r\n",
    "    xcorr = XCorr(metadata, xcorr_configurator.get_configuration(), regressor)\r\n",
    "    xcorr.fit(input_data)\r\n",
    "\r\n",
    "    if output_graph_file is None:\r\n",
    "        output_graph_file = \"/tmp/polaris_graph.json\"\r\n",
    "\r\n",
    "    metadata = PolarisMetadata({\"satellite_name\": source})\r\n",
    "    graph = PolarisGraph(metadata=metadata)\r\n",
    "    graph.from_heatmap(xcorr.importances_map, graph_link_threshold)\r\n",
    "    with open(output_graph_file, 'w') as graph_file:\r\n",
    "        graph_file.write(graph.to_json())\r\n",
    "\r\n",
    "\r\n",
    "def normalize_dataframe(dataframe):\r\n",
    "    \"\"\"\r\n",
    "        Apply dataframe modification so it's compatible\r\n",
    "        with the learn module. The time column is first\r\n",
    "        set as the index of the dataframe. Then, we drop\r\n",
    "        the time column.\r\n",
    "\r\n",
    "        :param dataframe: The pandas dataframe to normalize\r\n",
    "        :type dataframe: pd.DataFrame\r\n",
    "        :return: Pandas dataframe normalized\r\n",
    "        :rtype: pd.DataFrame\r\n",
    "    \"\"\"\r\n",
    "    dataframe.index = dataframe.time\r\n",
    "    dataframe.drop(['time'], axis=1, inplace=True)\r\n",
    "\r\n",
    "    return dataframe\r\n",
    "\r\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file 'C:\\Users\\manni\\Desktop\\VIU\\TFM\\repo\\Improve-MBSE-ML\\mlruns\\1\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 261, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 344, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 176, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\manni\\Desktop\\VIU\\TFM\\repo\\Improve-MBSE-ML\\mlruns\\1\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '2'. Detailed error Yaml file 'C:\\Users\\manni\\Desktop\\VIU\\TFM\\repo\\Improve-MBSE-ML\\mlruns\\2\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 261, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 344, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 176, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\manni\\Desktop\\VIU\\TFM\\repo\\Improve-MBSE-ML\\mlruns\\2\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/html": "<style>\n</style>\n<div class=\"enlighten\">\n  <div class=\"enlighten-bar\">\n    <pre>Columns 100%|| 170/170 [01:20&lt;00:00, 2.14 columns/s]</pre>\n  </div>\n</div>\n",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "#GENERA EL GRAFO DE LIGHTSAIL2\r\n",
    "cross_correlate(\"lightsail_dataset.csv\", \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest\")\r\n",
    "cross_correlate(\"lightsail_dataset.csv\", \"RandomForest\")\r\n",
    "print(\"AdaBoost\")\r\n",
    "cross_correlate(\"lightsail_dataset.csv\", \"AdaBoost\")\r\n",
    "print(\"Extra trees\")\r\n",
    "cross_correlate(\"lightsail_dataset.csv\", \"ExtraTrees\")\r\n",
    "print(\"Gradient boosting\")\r\n",
    "cross_correlate(\"lightsail_dataset.csv\", \"GradientBoosting\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python392jvsc74a57bd0de072921dc87486613898b1ef56959cc98c50a630fb49de1898fb32d92a683cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "de072921dc87486613898b1ef56959cc98c50a630fb49de1898fb32d92a683cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}